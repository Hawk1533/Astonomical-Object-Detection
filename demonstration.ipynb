{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Данный ноутбук решает задачу детектирования астрономических объектов:\n",
    "0.На данный момент точно работает только на srg из пользователя kolosovi\n",
    "1.Задать параметры (или использовать мои) в configs. \n",
    "2.Запустить ячейки в секция 3 и 4. Там код модели и обработки данных\n",
    "4.Запустить код в секции 5: настроить размер датасета, пути ко входным данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import all libraries\n",
    "Most are in libs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/kolosovi/work/all_notebooks/')\n",
    "sys.path.insert(0, '/home/kolosovi')\n",
    "\n",
    "import erospy\n",
    "from libs import *\n",
    "\n",
    "\n",
    "importlib.reload(erospy)\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager().update('notebook', {'limit_output': 100000000000000000})\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create config class\n",
    "All file path work, preprosessing and detection settings are here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "code_folding": [
     12,
     16,
     20,
     135,
     137
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, data_type, dataset_type, remove_old = False):\n",
    "        #data\n",
    "        self.data_type = data_type\n",
    "        \n",
    "        #Depending on the type of dataset - select a path for data. Assume that all data is there:\n",
    "        # -photon files\n",
    "        # -simput files\n",
    "        \n",
    "        #train - train dataset\n",
    "        #test - test dataset\n",
    "        #cluster - cluster dataset\n",
    "        if data_type == 'train':\n",
    "            self.data_path = '/srg/a1/work/kate/erosita/agn/2.4.2/1e17_for_mesh/'\n",
    "            self.noize_path = '/srg/a1/work/kate/erosita/bkg/for_mesh'\n",
    "            self.simput_file = os.path.join(self.data_path , '%i_agncat.simput')\n",
    "        elif data_type == 'test':\n",
    "            self.data_path = '/srg/a1/work/kate/erosita/agn/2.4.2/1e17/' #0_agncat.simput'\n",
    "            self.noize_path = '/srg/a1/work/kate/erosita/bkg/for_sim/' #bkg_?.fits'\n",
    "            self.simput_file = os.path.join(self.data_path , '%i_agncat.simput')\n",
    "        elif data_type == 'cluster':\n",
    "            self.data_path = '/srg/a1/work/kate/erosita/clusters/for_rodion' \n",
    "            self.noize_path = '/srg/a1/work/kate/erosita/bkg/for_sim/' #bkg_?.fits'\n",
    "            self.simput_file = os.path.join(self.data_path , '%i_clusters.simput') \n",
    "\n",
    "        #Now when specified directories, it's time to define file name patterns in this directories\n",
    "        self.ph_ero_file = os.path.join(self.data_path , '%i_4yr_ccdall_eroevt.fits')\n",
    "        self.ph_evt_file = os.path.join(self.data_path , '%i_4yr_ccdall_evt.fits')\n",
    "        self.noize_file = os.path.join(self.noize_path , 'bkg_%i.fits')\n",
    "        \n",
    "        #Just for clusters\n",
    "        self.cl_data_path = '/srg/a1/work/kate/erosita/clusters/for_rodion'\n",
    "        self.cl_simput_file = os.path.join(self.cl_data_path , '%i_clusters.simput') \n",
    "        self.cl_ph_ero_file = os.path.join(self.cl_data_path , '%i_4yr_ccdall_eroevt.fits')\n",
    "        self.cl_ph_evt_file = os.path.join(self.cl_data_path , '%i_4yr_ccdall_evt.fits')\n",
    "        \n",
    "        \n",
    "        self.work_path = '/home/kolosovi/work'\n",
    "        \n",
    "        \n",
    "        #path for esass results\n",
    "        self.esass_res_path = '/srg/a1/work/medvedev/agn_eSASS_190220_noEXT'\n",
    "        self.nn_res_path = os.path.join(self.work_path, 'data/my_output/final')\n",
    "        self.nn_res_path_noize = os.path.join(self.work_path, 'data/my_output/final_noize')\n",
    "        self.nn_res_path_nonoize = os.path.join(self.work_path, 'data/my_output/final_nonoize')\n",
    "        \n",
    "        #data input for nn paths\n",
    "        self.model_path = os.path.join(self.work_path, 'data/models/') \n",
    "        self.exposure_file = os.path.join(self.work_path, 'data/exposure/exp.fits')\n",
    "        self.telescope_path = os.path.join(self.work_path, 'data/telescope/')\n",
    "        self.wcs_file = os.path.join(self.work_path, 'data/projection_image.fits')\n",
    "        self.valid_frames_file = os.path.join(self.work_path, 'data/valid_frames.npy')\n",
    "        self.all_frames_file = os.path.join(self.work_path, 'data/all_frames.npy')\n",
    "        self.boxlist_file = os.path.join(self.esass_res_path, 'sim_0/BoxDetSourceListL.fits')\n",
    "        \n",
    "        #Dataset\n",
    "        self.save_train_data = False\n",
    "        self.dataset_type = dataset_type\n",
    "        self.dataset_path = os.path.join(f'/data/kolosovi/dataset_{self.dataset_type}/')\n",
    "        \n",
    "        if dataset_type == 'tmp' or remove_old:\n",
    "            if os.path.exists(self.dataset_path):\n",
    "                print(f'Erasing {self.dataset_path}')\n",
    "                shutil.rmtree(self.dataset_path)\n",
    "            os.makedirs(self.dataset_path)\n",
    "        \n",
    "        #create dir for dataset if not exists \n",
    "        d = os.path.dirname(self.dataset_path)\n",
    "        if not os.path.exists(d):\n",
    "                os.makedirs(d)\n",
    "        \n",
    "        self.dataset_file = os.path.join(self.dataset_path , 'df_%d_frame_%d.npy')\n",
    "        self.save_ims = False,\n",
    "\n",
    "        #--------------Preprosessing params-------------------------------------------\n",
    "        #KDE\n",
    "        self.border_KDE = False          \n",
    "        self.high_border_weight = False \n",
    "        self.KDE_bandwidth = 7\n",
    "        self.p_mask = 0.0016\n",
    "            #0.0016, may be i changed something. but it's too big now.\n",
    "            #0.0007 also may be to big\n",
    "            #old 0.0003 value leads to too big blobs in prediction \n",
    "\n",
    "        #PHOTONS\n",
    "        self.remove_null_pha = False\n",
    "        self.photon_limit_cut = False\n",
    "        self.photon_limit = 15 #Delete object if has < photon_limit\n",
    "        self.conf_limit = 2.3 * (10**-15)\n",
    "        self.min_flux = 2.3 * (10**-15) #confusion limit, objects with flux<min_flux - noize\n",
    "        #flux_limit = [2.3 * 10**-15, 1.1 * 10**-14], #, 4.4 * 10**-14],\n",
    "        self.flux_limit = [2.3 * (10**-15)]\n",
    "\n",
    "        #INPUT IMAGE\n",
    "        self.channels_N = 32 #always pow of 2\n",
    "        self.full_energy_channel = False\n",
    "        self.pha_channels_N = 8\n",
    "        self.offset_channel = True            \n",
    "        self.offset_channels_N = 4\n",
    "        #max_PHA = 960, #for channel size\n",
    "        self.sky_size = 2680 #cut df to this size by X,Y\n",
    "        self.P0 = 0 #starting from P0\n",
    "        self.object_weight = 1\n",
    "        self.add_noize = True\n",
    "        self.n_src = 100 #for colors\n",
    "\n",
    "        #SOURCES\n",
    "        self.correct_centers = False\n",
    "        self.esaas_thres_list = [1,2,3,8,10,13,16,20,30]\n",
    "        self.unet_thres_list_big = [0.07179278, 0.22292863, 0.40038235]\n",
    "        self.unet_thres_list = [0.5,0.55,0.67,0.76,0.82, 0.89, 0.94]\n",
    "\n",
    "        #--------------Postprosessing params-------------------------------------------\n",
    "        self.verbose = False\n",
    "        self.blob_thres = 8\n",
    "        self.gauss_output = False\n",
    "        self.gauss_size = 3\n",
    "        \n",
    "        #BOXLIST PARAMS\n",
    "        #for blobs and coordinates\n",
    "        self.save_boxlist_k = 3 #3x row duplicating\n",
    "        self.min_object_p = 0.2 #n't take to blob if lower\n",
    "        self.min_center_p = 0.8\n",
    "        self.min_blob_pixels = 35 #remove blob if it's less then 10 pixels\n",
    "        self.min_photons_in_blob = 14\n",
    "        #for noize\n",
    "        self.mean_ECF = 1.87 * 1e-12 #for flux conversion\n",
    "        self.exp_k = 1.5 * 2.561900e-10 / 3.228494e-13  #just divided original flux and experimental flux\n",
    "        self.noize_bound = 0.2 # <0.2 this is fucking noize - need it to count noize mean across image\n",
    "        \n",
    "\n",
    "        #args['KDE_bandwidth'] = 3\n",
    "        #args['p_mask'] = 0.0016 \n",
    "\n",
    "        \n",
    "    def __getitem__(self,key):\n",
    "        return getattr(self,key)\n",
    "    def __setitem__(self, key, value):\n",
    "        self.__dict__[key] = value\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load U-net model\n",
    "the final version, from file. no training here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     1,
     3,
     5,
     7,
     12,
     18,
     21,
     26,
     42
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Metrics\n",
    "def TP(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "def TP_FN(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "def TP_FP(y_true, y_pred):\n",
    "    return K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "def weight_loss(y_true, y_pred, weights):\n",
    "    return K.binary_crossentropy(y_true, y_pred) * weights\n",
    "\n",
    "\n",
    "def wrapped_partial(func, *args, **kwargs):\n",
    "    partial_func = partial(func, *args, **kwargs)\n",
    "    update_wrapper(partial_func, func)\n",
    "    return partial_func\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "def unet3(n_filters, dropout=0.5, batchnorm=True, \n",
    "          input_size = (512,512,32),pretrained_weights = None, weight_size = (512,512)):\n",
    "    \n",
    "    input_layer = Input(input_size,name='image')\n",
    "    weights_tensor = Input(weight_size,name='weights')\n",
    "    \n",
    "    #CONV -> BATCH -> ACTIVATION -> POOL -> DROPOUT\n",
    "        # contracting path\n",
    "    c1 = conv2d_block(input_layer, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "    p5 = Dropout(dropout)(p5)\n",
    "    \n",
    "    c6 = conv2d_block(p5, n_filters=n_filters*32, kernel_size=3, batchnorm=batchnorm)\n",
    "    p6 = MaxPooling2D(pool_size=(2, 2)) (c6)\n",
    "    p6 = Dropout(dropout)(p6)\n",
    "    \n",
    "    #--------------\n",
    "    #8x8\n",
    "    c7 = conv2d_block(p6, n_filters=n_filters*64, kernel_size=3, batchnorm=batchnorm)\n",
    "    #4x4\n",
    "    \n",
    "    #-------------------\n",
    "    \n",
    "    # expansive path\n",
    "    u8 = Conv2DTranspose(n_filters*32, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c6])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*32, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*16, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c5])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u10 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c9)\n",
    "    u10 = concatenate([u10, c4])\n",
    "    u10 = Dropout(dropout)(u10)\n",
    "    c10 = conv2d_block(u10, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u11 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c10)\n",
    "    u11 = concatenate([u11, c3], axis=3)\n",
    "    u11 = Dropout(dropout)(u11)\n",
    "    c11 = conv2d_block(u11, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)   \n",
    "    \n",
    "    u12 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c11)\n",
    "    u12 = concatenate([u12, c2], axis=3)\n",
    "    u12 = Dropout(dropout)(u12)\n",
    "    c12 = conv2d_block(u12, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)  \n",
    "    \n",
    "    u13 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c12)\n",
    "    u13 = concatenate([u13, c1], axis=3)\n",
    "    u13 = Dropout(dropout)(u13)\n",
    "    c13 = conv2d_block(u13, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)  \n",
    "    \n",
    "    ans = Conv2D(1, 1, activation = 'sigmoid', name='output')(c13)\n",
    "    \n",
    "    cl4 = wrapped_partial(weight_loss, weights=weights_tensor)\n",
    "    \n",
    "    model = Model(input = [input_layer, weights_tensor], output = ans)\n",
    "    \n",
    "    #optimizer = Adam(lr = 1e-4)\n",
    "    #optimizer = SGD(lr=1e-4, momentum=0.1, decay=0.0, nesterov=False)\n",
    "    #optimizer =SGD(lr=0.001, momentum=0.5, decay=0.0, nesterov=True)\n",
    "    optimizer = Adagrad()\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss = cl4, \n",
    "                  metrics = [precision,recall, TP, TP_FN, TP_FP])\n",
    "    \n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(args.model_path, 'unet_new_v19_ADAGRAD.hdf5')\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "model = unet3(pretrained_weights = model_path, \n",
    "              n_filters = 32, \n",
    "              input_size = (512,512,args['channels_N']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare input files\n",
    "using all params from arg variable (section 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "code_folding": [
     86,
     137,
     181,
     210,
     268,
     273,
     300,
     323,
     342,
     369,
     386,
     422,
     454,
     460,
     474,
     499,
     504,
     516,
     519,
     541,
     543,
     547,
     551,
     560,
     626,
     643,
     789
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "#  A Class for dataset generation. It read all data to samples structure.\n",
    "############################################################\n",
    "class Dataset():\n",
    "    def __init__(self, size=0, mode='train'):\n",
    "        self.size = size\n",
    "        self.mode = mode #train or test\n",
    "        self.mode_path = 'test_ero/' if mode != 'train' else 'train_ero/'\n",
    "        self.samples = []\n",
    "        self.dfs_n = []\n",
    "        self.sam_df = {} \n",
    "        self.dfs = {}\n",
    "        #Path work\n",
    "        \n",
    "        #self.stat = pd.read_excel('unet_v1_stat.xlsx')\n",
    "        #self.stat = self.stat.iloc[0:0]  \n",
    "        \n",
    "        hdulist = fits.open(args['wcs_file'])\n",
    "        self.my_wcs = wcs.WCS(hdulist[0].header)\n",
    "        \n",
    "    # Full data creation\n",
    "    def prepare(self, save_to_disk = True): #saves all data to samples\n",
    "        self.prepare_telescope()\n",
    "        for i in range(self.size): #per dfs     \n",
    "            all_sample_found = True\n",
    "            self.dfs_n.append(i)\n",
    "            self.sam_df[i] = []\n",
    "            n = i\n",
    "            \n",
    "            #Read data     \n",
    "            self.ph_ero_file = args.ph_ero_file % i\n",
    "            self.ph_evt_file = args.ph_evt_file % i\n",
    "            self.simput_file = args.simput_file % i\n",
    "            self.noize_file = args.noize_file % i\n",
    "\n",
    "            print('Current ERO', args.ph_ero_file % i)\n",
    "            print('Current EVT', args.ph_evt_file % i)\n",
    "            print('Current SIMPUT', args.simput_file % i)\n",
    "            print('Current NOIZE', args.noize_file % i)\n",
    "            \n",
    "            #don't need to read all data if all samples are saved on disk already\n",
    "            all_sample_found = False\n",
    "            df, simput = self.read_batch_data(n)\n",
    "            self.dfs[i] = df\n",
    "            \n",
    "            #Read frames from file!\n",
    "            \n",
    "            if self.mode == 'test':\n",
    "                print('Reading test frames')\n",
    "                frames = self.get_all_frames(df)\n",
    "                #frames = [Frame(**dct) for dct in np.load(args['all_frames_file'])]\n",
    "            else:\n",
    "                print('Reading train frames')\n",
    "                frames = [Frame(**dct) for dct in np.load(args['valid_frames_file'])]\n",
    "                \n",
    "            self.frames = frames\n",
    "            \n",
    "            print (\"FRAMES IN THIS DF\", len(frames))\n",
    "\n",
    "            for j, frame in enumerate(frames):\n",
    "                sample_file = args.dataset_file % (i, j)\n",
    "                \n",
    "                self.sam_df[i].append(len(self.samples))\n",
    "                \n",
    "                if os.path.isfile(sample_file): #we already have this file!\n",
    "                    print(len(self.samples), str(frame), 'found')\n",
    "                    s = Sample(n = n, frame_i = j, mode = self.mode)\n",
    "                    s.load_from_file(sample_file)\n",
    "                    \n",
    "                else: #have to count\n",
    "                    #if at least one sample in not found - than we have to read all data\n",
    "                    if all_sample_found:\n",
    "                        df, simput = self.read_batch_data() \n",
    "                        all_sample_found = False\n",
    "                        \n",
    "                    print(len(self.samples), str(frame), 'not found')\n",
    "                    s = Sample(df = df, simput = simput,frame = frame, n = n, frame_i = j, mode = self.mode)\n",
    "                    s.prepare()\n",
    "                    if save_to_disk:\n",
    "                        s.save_to_file(file = sample_file)\n",
    "                \n",
    "                self.samples.append(s)\n",
    "                \n",
    "                #Steps\n",
    "                if len(self.samples) >= self.size:\n",
    "                    return \n",
    "    def data_generator(self, save_to_disk = True, start_from = 0): #same as for prepare, but generator\n",
    "        self.prepare_telescope()\n",
    "        start = 0\n",
    "        for i in range(len(self.dfs_names)): #per dfs   \n",
    "            if start < start_from: #skip while not get start from\n",
    "                start += 25\n",
    "                continue\n",
    "                \n",
    "            all_sample_found = True\n",
    "            n = re.findall(r'\\d+', self.sim_names[i])[0]\n",
    "            self.dfs_n.append(n)\n",
    "            self.sam_df[n] = []\n",
    "            \n",
    "            #Read data\n",
    "            df_path  = self.cur_photon_path + self.dfs_names[i]  \n",
    "            sim_path = self.cur_simput_path + self.sim_names[i]\n",
    "            print('Current DF', df_path)\n",
    "            print('Current SIMPUT', sim_path)\n",
    "            #don't need to read all data if all samples are saved on disk already\n",
    "            #df, simput = self.read_batch_data(df_path, sim_path, min_flux = args['min_flux'])\n",
    "            \n",
    "            #Read frames from file!\n",
    "            frames = [Frame(**dct) for dct in np.load(args['frames_path'])]\n",
    "            #frames = self.get_valid_frames(df)\n",
    "            print (\"FRAMES IN THIS DF\", len(frames))\n",
    "\n",
    "            for j, frame in enumerate(frames):\n",
    "                sample_file = self.data_dir+\"df_{n}_frame_{j}.npy\".format(n=n,j=j)\n",
    "                self.sam_df[n].append(len(self.samples))\n",
    "                \n",
    "                if os.path.isfile(sample_file): #we already have this file!\n",
    "                    print(len(self.samples), str(frame), 'found')\n",
    "                    s = Sample()\n",
    "                    s.load_from_file(sample_file)\n",
    "                    \n",
    "                else: #have to count\n",
    "                    #if at least one sample in not found - than we have to read all data\n",
    "                    if all_sample_found:\n",
    "                        df, simput = self.read_batch_data(df_path, sim_path, min_flux = args['min_flux']) \n",
    "                        all_sample_found = False\n",
    "                        \n",
    "                    print(len(self.samples), str(frame), 'not found')\n",
    "                    s = Sample(df, simput, frame)\n",
    "                    s.prepare()\n",
    "                    if save_to_disk:\n",
    "                        s.save_to_file(file = sample_file)\n",
    "                    #self.samples.append(s.generate_data(mode = self.mode))\n",
    "\n",
    "                yield s.generate_data(mode = self.mode)        \n",
    "                    \n",
    "    #  Data reading and preprocessing\n",
    "    def read_batch_data(self, n):\n",
    "        df = self.prepocess_photons(ffile = self.ph_ero_file, ero = True)\n",
    "        simput = self.read_simput(ffile = self.simput_file)\n",
    "        \n",
    "        simput['EXT'] = np.zeros(len(simput))\n",
    "        \n",
    "        if args.join_cluster and args.data_type != 'cluster':\n",
    "            print(f'Adding cluster data to {args.data_type}')\n",
    "            \n",
    "            #reselect files\n",
    "            self.ph_ero_file = args.cl_ph_ero_file % n\n",
    "            self.ph_evt_file = args.cl_ph_evt_file % n\n",
    "            self.simput_file = args.cl_simput_file % n\n",
    "            \n",
    "            df_cl = self.prepocess_photons(ffile = self.ph_ero_file, ero = True)\n",
    "            simput_cl = self.read_simput(ffile = self.simput_file)\n",
    "            simput_cl['EXT'] = np.ones(len(simput_cl))\n",
    "            simput_cl['SRC_ID'] = simput_cl['SRC_ID'].apply(lambda src_id: src_id*1000000)\n",
    "            df_cl = df_cl.query('SRC_ID!=-1')\n",
    "            df_cl['SRC_ID'] = df_cl['SRC_ID'].apply(lambda src_id: src_id*1000000)\n",
    "\n",
    "            self.debug_simput = simput_cl\n",
    "            self.debug_df = df_cl\n",
    "            \n",
    "            print(f'CLUST LEN {len(simput_cl)}')\n",
    "            \n",
    "            #what if src_id are same?\n",
    "            df = pd.concat([df, df_cl])\n",
    "            simput = pd.concat([simput, simput_cl])\n",
    "            \n",
    "            print(f\"CLUST LEN {len(simput.query('EXT == 1'))}\")\n",
    "            \n",
    "        print('CURRENT MIN FLUX', args.min_flux)\n",
    "        df,simput = self.cut_data(df, simput, args.min_flux,ret_simput = True)      \n",
    "        self.simput = simput\n",
    "        self.df = df\n",
    "                  \n",
    "        print(f\"CLUST LEN {len(simput.query('EXT == 1'))}\")\n",
    "    \n",
    "        return df, simput     \n",
    "\n",
    "    ############################################################\n",
    "    #  Low level processing\n",
    "    ############################################################\n",
    "    def read_photons(self, ffile, ero = False):\n",
    "        #Data reading\n",
    "        with fits.open(ffile, memmap=True) as hdu:\n",
    "            data = hdu[1].data\n",
    "\n",
    "        df = pd.concat([\n",
    "            pd.DataFrame(data.field(\"RA\").byteswap().newbyteorder(),columns=['RA']),\n",
    "            pd.DataFrame(data.field(\"DEC\").byteswap().newbyteorder(),columns=['DEC']),\n",
    "            #pd.DataFrame(data.field(\"RAWX\").byteswap().newbyteorder(),columns=['RAWX']), #new\n",
    "           # pd.DataFrame(data.field(\"RAWY\").byteswap().newbyteorder(),columns=['RAWY']), #new\n",
    "            #pd.DataFrame(data.field(\"PHA\").byteswap().newbyteorder(),columns=['PHA']),\n",
    "            pd.DataFrame(data.field(\"TIME\").byteswap().newbyteorder(),columns=['TIME'])\n",
    "        ], axis=1)\n",
    "\n",
    "\n",
    "        if ero:\n",
    "            df = pd.concat([df, \n",
    "                pd.DataFrame(data.field(\"ENERGY\").byteswap().newbyteorder(),columns=['SIGNAL'])\n",
    "         ], axis = 1)     \n",
    "\n",
    "        else: #not in evt files we also have ph and src ids'\n",
    "            df = pd.concat([df, \n",
    "                pd.DataFrame(data.field(\"SIGNAL\").byteswap().newbyteorder(),columns=['SIGNAL']),\n",
    "                pd.DataFrame(data.field(\"PH_ID\").byteswap().newbyteorder(),columns=['PH_ID', 'ZERO_COL'])['PH_ID'],\n",
    "                pd.DataFrame(data.field(\"SRC_ID\").byteswap().newbyteorder(),columns=['SRC_ID','ZERO_COL'])['SRC_ID']\n",
    "         ], axis = 1)\n",
    "\n",
    "\n",
    "        return df   \n",
    "    def prepocess_photons(self, ffile, ero = False, read_evt = True):\n",
    "        df = self.read_photons(ffile, ero)\n",
    "        \n",
    "        #Delete src with photons < limit and PHA == -1\n",
    "        if args['verbose'] and not(ero):\n",
    "            print('Read full df')\n",
    "            print('На всей картинке, объектов:' , str(len(df['SRC_ID'].unique())), 'Фотонов: ', len(df))  \n",
    "        if args['remove_null_pha']:\n",
    "            df = df[df['PHA']!=-1]\n",
    "            if args['verbose'] and not(ero):\n",
    "                print('На всей картинке после удаления PHA -1  объектов:' , str(len(df['SRC_ID'].unique())), 'Фотонов: ', len(df))  \n",
    "        if args['photon_limit_cut'] and not(ero):\n",
    "            photon_n = df.groupby(['SRC_ID']).count().reset_index()\n",
    "            true_objects = list(photon_n[photon_n['RA'] > args['photon_limit']]['SRC_ID'].unique())\n",
    "            df = df[df['SRC_ID'].isin(true_objects)]\n",
    "\n",
    "        #Adds x,y to df #Use WCS params from one of the erbox images\n",
    "        df = self.projectXY(df)    \n",
    "        \n",
    "        df = df[['RA', 'DEC','SIGNAL', 'TIME', 'X', 'Y']]\n",
    "        \n",
    "        \n",
    "        df = self.add_telectope_dist(df)\n",
    "        \n",
    "        print('FIRST READ',len(df))\n",
    "        \n",
    "        noize_df = self.add_noize(df) #creates\n",
    "        if not(args['add_noize']): #it is easier to cut df then to remove all this code\n",
    "            noize_df = noize_df[:1]\n",
    "        \n",
    "        \n",
    "        #noize_df = self.add_telectope_dist(noize_df)\n",
    "        noize_df['OFFSET'] = sample_from_distribution(df['OFFSET'], len(noize_df))\n",
    "\n",
    "        print('FIRST READ',len(df))\n",
    "        #if ero is true than we should also read evt and get src_id column there.\n",
    "        if ero:\n",
    "            print('CURRENT EVT', self.ph_evt_file)\n",
    "            evt = self.read_photons(self.ph_evt_file)\n",
    "            \n",
    "            df,noize_df = self.merge_ero_evt(df,evt,noize_df)\n",
    "        \n",
    "        print('SEC READ',len(df))\n",
    "        df = pd.concat([df, noize_df], axis = 0)\n",
    "\n",
    "        \n",
    "        #my custom scale SIGNAL ----> PHA and OFFSET ----> OFFSET_CHAN\n",
    "        scale = interp1d([500, 2000], [1,args['pha_channels_N']])\n",
    "        df['PHA'] = df['SIGNAL'].apply(lambda signal: int(np.round(scale(signal))))\n",
    "        scale = interp1d([df['OFFSET'].min(),df['OFFSET'].max()], [1,args['offset_channels_N']])\n",
    "        df['OFFSET_CHAN'] = df['OFFSET'].apply(lambda offset: int(np.round(scale(offset))))\n",
    "        df['PHOTON_TYPE'] = (df['PHA'] * df['OFFSET_CHAN']).astype(int)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.df =df.copy()\n",
    "        df = df[['RA', 'DEC','PHA', 'TIME', 'OFFSET', 'OFFSET_CHAN', 'X', 'Y', 'SRC_ID','PHOTON_TYPE']]\n",
    "        return self.cut_to_sky_size(df)\n",
    "    def cut_to_sky_size(self,df):\n",
    "        #df = df[(df.X >=10) & (df.X <=2690) & (df.Y >=10) & (df.Y <=2690)]\n",
    "        #df['X'] = df['X'] - min(df['X'])\n",
    "        #df['Y'] = df['Y'] - min(df['Y'])\n",
    "        return df\n",
    "    def merge_ero_evt(self,ero,evt,noize):\n",
    "        def f1 (x):\n",
    "            return float(\"%.4f\" % x)\n",
    "        def f2 (x):\n",
    "            num = str(x-min_time).split('.')\n",
    "            return int(num[0])# + '.' + num[1][:2])\n",
    "\n",
    "\n",
    "        #want to make a good conversion.\n",
    "        ero['DEC'] = ero['DEC'].apply(f1)\n",
    "        ero['RA'] = ero['RA'].apply(f1)\n",
    "        evt['DEC'] = evt['DEC'].apply(f1)\n",
    "        evt['RA'] = evt['RA'].apply(f1)\n",
    "        noize['DEC'] = noize['DEC'].apply(f1)\n",
    "        noize['RA'] = noize['RA'].apply(f1)\n",
    "        \n",
    "        min_time = 629434995\n",
    "        evt['TIME'] = evt['TIME'].apply(f2)\n",
    "        ero['TIME'] = ero['TIME'].apply(f2)\n",
    "        noize['TIME'] = noize['TIME'].apply(f2)\n",
    "        \n",
    "        merge = ero.merge(evt[['TIME', 'RA', 'DEC', 'SRC_ID']], on =['RA', 'DEC','TIME'], how = 'inner')\n",
    "        print('ERO LEN', len(ero))\n",
    "        print('EVT LEN', len(evt))\n",
    "        print('MERGE LEN', len(merge))\n",
    "\n",
    "        return merge, noize\n",
    "    def projectXY (self,df):\n",
    "        #Get wcs from random image\n",
    "        #print('WCS FROM', args['wcs_file'])\n",
    "\n",
    "        #According to mesch\n",
    "        assert (abs(self.my_wcs.wcs.cdelt[0] * self.my_wcs.wcs.cdelt[1] * 3600 * 1000) < 9)\n",
    "        #print ('PIXEL SIZE', abs(w.wcs.cdelt[0] * w.wcs.cdelt[1] * 3600 * 1000))\n",
    "\n",
    "        df = df[(df['RA'] >= 0) & (df['RA']<= 3)][ (df['DEC'] >= 0) & (df['DEC']<= 3) ]\n",
    "\n",
    "        df['X'], df['Y'] = self.my_wcs.all_world2pix(df['RA'], df['DEC'], 1) \n",
    "        \n",
    "        #df = df[(df.X >=10) & (df.X <=2690) & (df.Y >=10) & (df.Y <=2690)]\n",
    "        df = df.query(f'{args.P0} <= X < {args.P0 + args.sky_size} and {args.P0} <= Y < {args.P0 + args.sky_size}')\n",
    "        \n",
    "        #For absolute sky\n",
    "        #df['X'] -= df['X'].min()\n",
    "        #df['Y'] -= df['Y'].min()\n",
    "\n",
    "        df['X'] = df['X'].astype(np.int16)\n",
    "        df['Y'] = df['Y'].astype(np.int16)\n",
    "\n",
    "        return df\n",
    "    def read_simput(self,ffile):\n",
    "        with fits.open(ffile, memmap=True) as hdu:\n",
    "            #hdu.info()\n",
    "            data = hdu[1].data\n",
    "            #spec = hdu[3].data\n",
    "\n",
    "        #Skipped IMGROTA, IMGSCALE, SPECTRUM\n",
    "        simput = pd.concat([\n",
    "            pd.DataFrame(data.field(\"SRC_ID\").byteswap().newbyteorder(),columns=['SRC_ID']),\n",
    "            pd.DataFrame(data.field(\"RA\").byteswap().newbyteorder(),columns=['RA']),\n",
    "            pd.DataFrame(data.field(\"DEC\").byteswap().newbyteorder(),columns=['DEC']),\n",
    "            pd.DataFrame(data.field(\"E_MIN\").byteswap().newbyteorder(),columns=['E_MIN']),\n",
    "            pd.DataFrame(data.field(\"E_MAX\").byteswap().newbyteorder(),columns=['E_MAX']),\n",
    "            pd.DataFrame(data.field(\"FLUX\").byteswap().newbyteorder(),columns=['FLUX']),\n",
    "        ], axis=1)\n",
    "\n",
    "        simput['LOG_FLUX'] = np.log10(simput['FLUX'])\n",
    "        simput['FLUX_CLASS'] = pd.cut(simput['LOG_FLUX'], bins = np.linspace(-14.7, -11.8, 11), labels = np.arange(1,11))\n",
    "        return self.cut_to_sky_size(self.projectXY(simput))\n",
    "    def prepare_telescope(self): #read and sort data\n",
    "        print('Telescope data preparing')\n",
    "        #READ DATA\n",
    "        def read_telescope(ffile):\n",
    "            #Data reading\n",
    "            with fits.open(ffile, memmap=True) as hdu:\n",
    "                data = hdu[1].data\n",
    "\n",
    "            df = pd.concat([\n",
    "                pd.DataFrame(data.field(\"TIME\").byteswap().newbyteorder(),columns=['TIME']),\n",
    "                pd.DataFrame(data.field(\"RA\").byteswap().newbyteorder(),columns=['RA']),\n",
    "                pd.DataFrame(data.field(\"DEC\").byteswap().newbyteorder(),columns=['DEC']),\n",
    "            ], axis=1)\n",
    "\n",
    "            return df\n",
    "\n",
    "        tel = pd.DataFrame()\n",
    "        for ffile in sorted(os.listdir(args['telescope_path'])):\n",
    "            #print(ffile)\n",
    "            tmp = read_telescope(args['telescope_path'] + ffile)\n",
    "            tel = pd.concat([tel,tmp], axis=0)\n",
    "\n",
    "        #asof needs sorted data\n",
    "        tel = tel.sort_values('TIME').reset_index()\n",
    "        tel['TEL_TIME'] = tel['TIME']\n",
    "        tel['TIME'] = tel['TIME'].astype(float)\n",
    "        self.tel = tel \n",
    "    def add_telectope_dist (self, df):\n",
    "        df =  df.sort_values('TIME').reset_index()\n",
    "        df['PH_TIME'] = df['TIME']\n",
    "        \n",
    "        df['TIME'] = df['TIME'].astype(float)\n",
    "\n",
    "        df = pd.merge_asof(df, self.tel, on='TIME') \\\n",
    "                .rename(columns = {'RA_x':'RA', 'DEC_x':'DEC','RA_y':'TEL_RA', 'DEC_y':'TEL_DEC'}) \\\n",
    "                .drop(['index_y', 'index_x', 'level_0'], axis = 1, errors = 'ignore') \n",
    "\n",
    "        #Finally count distance\n",
    "        def dist(row):\n",
    "            return math.acos(math.cos(90-row['DEC']) * math.cos(90 - row['TEL_DEC']) \\\n",
    "                            + math.sin(90-row['DEC']) * math.sin(90 - row['TEL_DEC']) * math.cos(row['RA']-row['TEL_RA']))\n",
    "\n",
    "        df['OFFSET'] = df.apply(dist, axis = 1)\n",
    "        return df\n",
    "    def add_noize(self,df):\n",
    "        print('Noize preparing')\n",
    "        noize = fits.open(self.noize_file)[1].data\n",
    "        \n",
    "        \n",
    "\n",
    "        max_time, min_time = df['TIME'].max(), df['TIME'].min()\n",
    "        #min_sig, max_pha = df['PHA'].min(), df['PHA'].max()\n",
    "        time = list(df['TIME'])\n",
    "        \n",
    "        scale = interp1d([1,args['pha_channels_N']], [500,2000])\n",
    "\n",
    "        new_rows = []\n",
    "        for i in range(noize.shape[0]):\n",
    "            for j in range(noize.shape[1]):\n",
    "                for k in range(noize[i][j]):\n",
    "                    ph = {}\n",
    "                    ph['X'] = j #придется порпавить, это не мои картинки же\n",
    "                    ph['Y'] = i\n",
    "\n",
    "                    m = random.randint(0, len(df)-1)\n",
    "                    ph['TIME'] = df['TIME'].iloc[m]\n",
    "                    ph['RA'],ph['DEC'] = self.my_wcs.all_pix2world(ph['X'], ph['Y'],1)\n",
    "\n",
    "\n",
    "                    ph['SIGNAL'] = random.random() * 1500 + 500\n",
    "                    ph['SRC_ID'] = -1\n",
    "\n",
    "                    new_rows.append(ph)    \n",
    "        \n",
    "        noize_df = pd.DataFrame(new_rows)\n",
    "        return noize_df\n",
    "        #return pd.concat([df, pd.DataFrame(new_rows)], axis = 0)\n",
    "    \n",
    "    # flux < conf limit = noize -1\n",
    "    # conf limit < flux < min_flux - throw out\n",
    "    def cut_data(self, df_full, simput_full, min_flux, ret_simput = False): #Remove sources with flux < threshold\n",
    "        print('NOIZE PHOTONS N (before)',len(df_full[df_full['SRC_ID'] == -1]))\n",
    "        print(f\"$$$$ DF CHECK {len(df_full.query('SRC_ID == 800'))}\")\n",
    "        df = df_full.copy()\n",
    "\n",
    "        #Select object with flux < conf limit and set them to noize\n",
    "        self.simput_full = simput_full.copy()\n",
    "        noize_obj = list(simput_full[simput_full['FLUX'] < args['conf_limit']]['SRC_ID'])\n",
    "            \n",
    "        df.loc[df['SRC_ID'].isin(noize_obj), 'SRC_ID'] = -1 #SET THEM TO NOIZE\n",
    "        print(f\"$$$$ DF CHECK {len(df.query('SRC_ID == 800'))}\")\n",
    "              \n",
    "        #Remove objects with flux < min_flux\n",
    "        print(f\"--cut data CLUST LEN {len(simput_full.query('EXT == 1'))}\")      \n",
    "        simput = simput_full[simput_full['FLUX'] >= args['conf_limit']]\n",
    "        print(f\"--cut data CLUST LEN {len(simput.query('EXT == 1'))}\") \n",
    "        print('--EXAMPLE', df.iloc[0]['SRC_ID'])\n",
    "              \n",
    "        good_obj = list(simput['SRC_ID']) + [-1]\n",
    "        df = df[df['SRC_ID'].isin(good_obj)] \n",
    "        print(f\"$$$$ DF CHECK {len(df.query('SRC_ID == 800'))}\")\n",
    "        \n",
    "        #Remove objects from simput which don't have photons in df\n",
    "        good_obj = list(set(list(df['SRC_ID'])))\n",
    "        simput = simput[simput['SRC_ID'].isin(good_obj)] \n",
    "        print(f\"--cut data CLUST LEN {len(simput.query('EXT == 1'))}\") \n",
    "              \n",
    "        print(len(simput_full),\"objects overall; \", len(simput), \"objects with flux more than\", min_flux)\n",
    "        noize_n = len(df[df['SRC_ID'] == -1])\n",
    "        print('NOIZE PHOTONS N (after)', noize_n)\n",
    "        print('OBJECTS PHOTONS N (after)',len(df) - noize_n)\n",
    "        return df,simput\n",
    "    def cut_simput_flux(self, simput, flux):\n",
    "        return simput[simput['FLUX'] >= flux]\n",
    "\n",
    "    ############################################################\n",
    "    #  Frame cut work\n",
    "    ############################################################\n",
    "    def get_valid_frames(self,df): #Get without borders\n",
    "        sizeX = sizeY = 512\n",
    "        X,Y=sorted(df['X'].astype(int)),sorted(df['Y'].astype(int)) \n",
    "        xmin,xmax = X[int(len(X)*0.01)], X[int(len(X)*(1-0.01))]\n",
    "        ymin,ymax = Y[int(len(Y)*0.01)], Y[int(len(Y)*(1-0.01))]\n",
    "        n_tiles = int(min((xmax-xmin)/sizeX, (ymax-ymin)/sizeY))\n",
    "        frames = []\n",
    "        for cellX in range(n_tiles):\n",
    "            for cellY in range(n_tiles):\n",
    "                x0,y0 = xmin+cellX*sizeX, ymin+cellY*sizeY\n",
    "                x1,y1 = x0+sizeX, y0+sizeY\n",
    "                frames.append(Frame(x0,x1,y0,y1))\n",
    "\n",
    "        return frames\n",
    "    def get_all_frames(self,df): #Get all images with borders\n",
    "        sizeX = sizeY = 512\n",
    "        xmin,xmax = df['X'].min(), df['X'].max()\n",
    "        ymin,ymax = df['Y'].min(), df['Y'].max()\n",
    "        n_tiles = int((xmax-xmin)/sizeX + 1)\n",
    "        frames = []\n",
    "        for cellX in range(n_tiles):\n",
    "            for cellY in range(n_tiles):\n",
    "                x0,y0 = xmin+cellX*sizeX, ymin+cellY*sizeY\n",
    "                x1,y1 = x0+sizeX, y0+sizeY\n",
    "                if x1 > args['sky_size']:\n",
    "                    x1 = args['sky_size']\n",
    "                    x0 = x1 - sizeX\n",
    "                if y1 > args['sky_size']:\n",
    "                    y1 = args['sky_size']\n",
    "                    y0 = y1 - sizeY\n",
    "\n",
    "\n",
    "                frames.append(Frame(x0,x1,y0,y1))\n",
    "\n",
    "        return frames\n",
    "    \n",
    "    ############################################################\n",
    "    #  Statistics\n",
    "    ############################################################\n",
    "    def stat_simput_photons_per_object(self):\n",
    "        return self.samples[0].df.groupby('SRC_ID').agg({'RA': 'count'}). \\\n",
    "                                     reset_index().groupby('RA').count().reset_index(). \\\n",
    "                                     rename(columns = {'RA':'PHOTONS_IN_SRC', 'SRC_ID':'N_OBJECTS'}). \\\n",
    "                                     sort_values('PHOTONS_IN_SRC')\n",
    "    def stat_flux_from_photonons_per_object(self): #not works\n",
    "        #d с помощью groupby от df\n",
    "        d['NEW_RA'] = d['RA'].apply(lambda ra: (ra // 3) * 3)\n",
    "        means = d.groupby('NEW_RA').mean().reset_index()\n",
    "        #plt.xscale(\"log\")\n",
    "        plt.figure(figsize=(60,8))\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel('N photons')\n",
    "        sns.boxplot(x = 'NEW_RA', y = 'FLUX', data = d)\n",
    "        sns.lineplot(x = [0, 300], y =[data_gen_args['min_flux'],data_gen_args['min_flux']])\n",
    "        plt.savefig('11.jpg')\n",
    "    def predict_all(self,model):\n",
    "        for i in range(self.size):\n",
    "            self.samples[i].predict(model) \n",
    "    def merge_stats(self, model,model_path='unet'): #merge all stats from samples #merge stats from all samples. work just for one flux now\n",
    "        stats = []\n",
    "        for i in range(self.size):\n",
    "            self.samples[i].get_stat(model, model_path)\n",
    "            stats.append(self.samples[i].stat)\n",
    "        \n",
    "        self.stat = pd.concat(stats)\\\n",
    "               .groupby(['mode', 'thres', 'min_flux'])['TP','FP','FN','CP','PCP', 'object_pixels', 'N', 'all_ph', 'found_ph']\\\n",
    "               .sum().reset_index()\n",
    "\n",
    "        #Stat processing\n",
    "        self.stat = self.stat[self.stat['thres'] != 1]\n",
    "        self.stat['prec'] = self.stat['TP'] / self.stat['PCP'] \n",
    "        self.stat['rec'] = self.stat['TP'] / self.stat['CP'] \n",
    "        self.stat.drop_duplicates(inplace = True)\n",
    "        self.stat.sort_values(by = ['mode', 'min_flux', 'thres'], inplace = True)\n",
    "        self.stat['object_ratio'] = self.stat['object_pixels'] / (self.stat['N'] * 512**2)\n",
    "        self.stat['object_count_fraction'] = self.stat['found_ph'] / self.stat['all_ph'] \n",
    "       \n",
    "    ############################################################\n",
    "    #  File work\n",
    "    ############################################################\n",
    "    def save_to_file(self,file='ds_test.npy'):\n",
    "        np.save(file, self.__dict__)\n",
    "    def load_from_file(self, file): #init from dictionary\n",
    "        ds_dict = np.load(file)[()]\n",
    "        for k, v in ds_dict.items():\n",
    "            setattr(self, k, v)\n",
    "    def save_stat(self, file = \"unet_results/unet10_gauss7.xlsx\" ):\n",
    "        self.stat.to_excel(file)\n",
    "\n",
    "    #Here we save everything to boxlist.fits\n",
    "    def save_boxlists(self,  d = args['nn_res_path']):\n",
    "        #create detected tables for each sample\n",
    "        for i in tqdm_notebook(range(self.size)): \n",
    "            self.samples[i].boxlist()\n",
    "        #concatenate detected tables from samples to big boxlists\n",
    "        create_dir(args.nn_res_path)\n",
    "        for df_n, sam_ind in self.sam_df.items():\n",
    "            self.df_detected = pd.concat([self.samples[i].detected for i in sam_ind], axis = 0)   \n",
    "            self.save_boxlist(self.df_detected, d+f'/boxlist_{df_n}.fits')\n",
    "    def save_boxlist(self,src, file):\n",
    "            Nsrcs = len(src)\n",
    "            k = args['save_boxlist_k']\n",
    "            #Three columns to identify source #+\n",
    "            #c1   = fits.Column(name='id_src', array=np.repeat(np.arange(Nsrcs)+1.,k).astype(int), format='1J')\n",
    "            #c2   = fits.Column(name='id_inst', array=np.array([0,1,1]*Nsrcs), format='1J')\n",
    "            #c3   = fits.Column(name='id_band', array=np.array([0,0,1]*Nsrcs), format='1J')\n",
    "            # we will assume that net_counts is somewhat equivalent to scts\n",
    "            #c4   = fits.Column(name='scts',   array=np.repeat(src['SRC_CTS'],k),     format='1E')\n",
    "            #c5   = fits.Column(name='scts_err', array=np.repeat(src['SRC_CTS_ERR'],k), format='1E')\n",
    "            #c6   = fits.Column(name='box_cts',   array=np.repeat(src['BOX_CTS'],k),     format='1E')\n",
    "            #convert RA,DEC from wavcat to x,y values\n",
    "            #c7   = fits.Column(name='x_ima',   array=np.repeat(src['X'],k),     format='1E')\n",
    "            #c8   = fits.Column(name='x_ima_err', array=np.array([0.1]*Nsrcs*k), format='1E')\n",
    "            #c9   = fits.Column(name='y_ima',   array=np.repeat(src['Y'],k),     format='1E')\n",
    "            #c10  = fits.Column(name='y_ima_err', array=np.array([0.1]*Nsrcs*k), format='1E')\n",
    "            #likelihood = -np.log10(erfc(wavcathdus[1].data['SRC_SIGNIFICANCE']))\n",
    "            #print (likelihood[:5], wavcathdus[1].data['SRC_SIGNIFICANCE'][:5])\n",
    "            c11  = fits.Column(name='DET_LIKE_0', array=np.repeat(src['LIKE'],k), format='1E')\n",
    "            #c12  = fits.Column(name='bg_map', array=np.repeat(src['BKG_CTS'],k), format='1E')\n",
    "            #c13  = fits.Column(name='bg_raw', array=np.repeat(src['BKG_CTS'],k), format='1E')\n",
    "            #c14  = fits.Column(name='exp_map', array=np.repeat(src['MEAN_EXP_TIME'],k), format='1E')\n",
    "            c15  = fits.Column(name='ML_FLUX_0', array=np.repeat(src['FLUX'],k), format='1E')\n",
    "            c16  = fits.Column(name='ML_FLUX_ERR_0', array=np.repeat(src['FLUX_ERR'],k), format='1E')\n",
    "            #c17  = fits.Column(name='rate', array=np.repeat(src['NET_RATE'],k), format='1E')\n",
    "            #c18  = fits.Column(name='rate_err', array=np.repeat(src['NET_RATE_ERR'],k), format='1E')\n",
    "            c19  = fits.Column(name='RA', array=np.repeat(src['RA'],k), format='1E')\n",
    "            c20  = fits.Column(name='DEC', array=np.repeat(src['DEC'],k), format='1E')\n",
    "            #c21  = fits.Column(name='RADEC_ERR', array=np.repeat(src['RA_DEC_ERR'],k), format='1E')\n",
    "            #c22  = fits.Column(name='lII', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "            #c23  = fits.Column(name='bII', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "            #c24  = fits.Column(name='hr1', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "            #c25  = fits.Column(name='hr1_err', array=np.array([-999.9]*Nsrcs*k), format='1E')\n",
    "            #c26  = fits.Column(name='hr2', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "            #c27  = fits.Column(name='hr2_er', array=np.array([-999.9]*Nsrcs*k), format='1E')\n",
    "            ##c28  = fits.Column(name='hr3', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "            #c29  = fits.Column(name='hr3_err', array=np.array([-999.9]*Nsrcs*k), format='1E')\n",
    "            #c30  = fits.Column(name='vignetting', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "\n",
    "            #we need to estimate box_size from 3-sigma ellipse\n",
    "            # box_size = wavcathdus[1].data['R'].T\n",
    "            # mean_r   = 0.5*(box_size[0]+box_size[1])\n",
    "            # mean_r   = ((mean_r*0.05)/80)/3.\n",
    "            #c31  = fits.Column(name='box_size', array=np.repeat(src['BOX_SIZE'],k).astype(int), format='1J')\n",
    "            #c32  = fits.Column(name='eef', array=np.array([0.9]*Nsrcs*k), format='1E')\n",
    "            #c33  = fits.Column(name='dist_nn', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "\n",
    "            #EXT ZEROS\n",
    "            c34  = fits.Column(name='EXT', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "            #c35  = fits.Column(name='EXT_ERR', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "            #c36  = fits.Column(name='EXT_LIKE', array=np.array([0.]*Nsrcs*k), format='1E')\n",
    "\n",
    "            #colz = [c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,\n",
    "            #        c11,c12,c13,c14,c15,c16,c17,c18,c19,c20,\n",
    "            #        c21,c22,c23,c24,c25,c26,c27,c28,c29,c30,\n",
    "            #        c31,c32,c33,c34,c35,c36]\n",
    "            colz = [c11,c15,c16,c19,c20,c34]\n",
    "\n",
    "            header = fits.open(args.boxlist_file, memmap=True)[0].header #take it from other boxlist.fits\n",
    "\n",
    "            newprimary = fits.PrimaryHDU(header=header)\n",
    "            newcolumns = fits.BinTableHDU.from_columns(colz, header=header)\n",
    "            newcat = fits.HDUList([newprimary,newcolumns])\n",
    "            newcat.writeto(file, clobber=True)   \n",
    "        \n",
    "    #for general work ------------------\n",
    "    def group_ans(self):\n",
    "        self.ans = {}\n",
    "\n",
    "        for df_n, sam_ind in self.sam_df.items():\n",
    "            cur_ans = np.zeros(shape = (args.sky_size, args.sky_size))\n",
    "            \n",
    "            for ind in sam_ind:\n",
    "                frame = self.samples[ind].frame\n",
    "                cur_ans[frame.x0:frame.x1,frame.y0:frame.y1] = self.samples[ind].ans\n",
    "            \n",
    "            self.ans[df_n] = cur_ans.copy()\n",
    "    def save_boxlists2(self):\n",
    "        for df_n, cur_ans in self.ans.items():\n",
    "            src = self.boxlist(cur_ans, df_n)\n",
    "            self.cur_src =src\n",
    "            self.save_boxlist(src, args.nn_res_path+f'/boxlist_{df_n}.fits')\n",
    "    \n",
    "    def boxlist(self, cur_ans, df_n):\n",
    "        #Input: 2D numpy array data \n",
    "        #Output: list of blobs (blob - a list of points)\n",
    "        def get_blobs(data0, pmap): #data0 - centers, pmap - probability map\n",
    "            data = data0.copy()\n",
    "\n",
    "            blob,blobs = [],[]\n",
    "            sizeX, sizeY = data.shape\n",
    "\n",
    "            def get_near(x,y,data):\n",
    "                ans = []\n",
    "                for dx in [-1,0,1]:\n",
    "                    for dy in [-1,0,1]:\n",
    "                        nx,ny = x+dx,y+dy\n",
    "                        #Check if it is my center point or it's just less probable\n",
    "                        if (nx >=0 and nx < sizeX and ny>=0 and ny < sizeY) and data[nx][ny]!=2 and \\\n",
    "                            ((data[nx][ny]==1) or (pmap[x][y] >= pmap[nx][ny] >= args['min_object_p'])): #or it's just less probable\n",
    "\n",
    "                            data[nx][ny]=2\n",
    "                            ans.append((nx,ny))\n",
    "\n",
    "                if (x,y) in ans:\n",
    "                    ans.remove((x,y))\n",
    "                return ans\n",
    "\n",
    "            def array_search(x,y,data):\n",
    "                ans,cur = [],[]\n",
    "\n",
    "                if data[x][y] == 1:\n",
    "                    cur.append((x,y))\n",
    "\n",
    "                while cur!=[]:\n",
    "                    ans += cur\n",
    "                    prev = cur.copy()\n",
    "                    cur = []\n",
    "\n",
    "                    for pnt in prev:\n",
    "                        cur+=get_near(*pnt, data)\n",
    "\n",
    "                return ans \n",
    "\n",
    "            for x in range(sizeX):\n",
    "                for y in range(sizeY):\n",
    "                    if data[x][y] == 1:\n",
    "                        blob = []\n",
    "                        blob+=array_search(x,y,data) #it is appending to blob\n",
    "                        blobs.append(blob)\n",
    "                        #print('Blob',blobs)\n",
    "            return blobs #fitst method just to add initial blobs    \n",
    "\n",
    "        #------get some blobs from ans----------\n",
    "        centers = cur_ans.copy()\n",
    "        pmap = cur_ans.copy()\n",
    "\n",
    "        pmap = gaussian_filter(pmap, sigma = 1)\n",
    "\n",
    "        centers = (centers == maximum_filter(centers,footprint=np.ones((9,9)))) * (pmap > args['min_center_p'])\n",
    "        centers = convolve(centers, np.ones((3,3)), mode='constant', cval=0.0)\n",
    "        centers = centers.astype(int)\n",
    "\n",
    "        blobs = get_blobs(centers, pmap)\n",
    "        print('All blobs', len(blobs))\n",
    "        #cut small blobs\n",
    "        blobs = [blob for blob in blobs if len(blob) > args['min_blob_pixels']]\n",
    "        print('After min blob pixels cut', len(blobs))\n",
    "\n",
    "        \n",
    "        \n",
    "        #-------count noize mean for later use\n",
    "        df = self.dfs[df_n].copy()\n",
    "\n",
    "        def is_noize(row):\n",
    "            return pmap[int(row['X'])][int(row['Y'])] < args['noize_bound']\n",
    "\n",
    "        df['is_noize'] = df.apply(is_noize, axis = 1)\n",
    "        df = df.query('is_noize == True')\n",
    "\n",
    "        S = (pmap < args['noize_bound']).astype(int).sum() #n of noize pixels\n",
    "        noize_p = len(df) / S\n",
    "        print('current noize p',noize_p)\n",
    "        \n",
    "        #-------convert blobs to dataframe src with all information\n",
    "        #OK, now we have some blobs. Extract center and flux from each blob know\n",
    "        src = pd.DataFrame(columns=['FLUX', 'X', 'Y', 'SRC_CTS', 'BKG_CTS'])\n",
    "\n",
    "        #for each blob we need to count number of photons in it \n",
    "        df = self.dfs[df_n].copy()\n",
    "        small_blob_N = 0\n",
    "        for blob in blobs:\n",
    "            cur_blob = np.array(blob).T\n",
    "            x0,x1,y0,y1 = cur_blob[0].min(), cur_blob[0].max(), cur_blob[1].min(), cur_blob[1].max()\n",
    "            cur_df = df[df['X'].between(x0,x1) & df['Y'].between(y0,y1)]\n",
    "\n",
    "            X = cur_blob[0]\n",
    "            Y = cur_blob[1]\n",
    "            div = X / Y\n",
    "            res = X - Y\n",
    "            ans = df.query('X in @X and Y in @Y and X/Y in @div')\n",
    "\n",
    "            if len(ans) < args['min_photons_in_blob']:\n",
    "                small_blob_N +=1\n",
    "                continue\n",
    "\n",
    "            blob_pixels = len(blob)\n",
    "            bkg_cts_count = int(noize_p * blob_pixels)\n",
    "            cts = len(ans)\n",
    "            src_cts = cts - bkg_cts_count #len(ans[ans['SRC_ID']!=-1])\n",
    "            bkg_cts_correct = len(ans[ans['SRC_ID']==-1]) #need to estimate from image\n",
    "\n",
    "            box_cts = len(cur_df)\n",
    "            box_size = int((x1-x0+y1-y0+2)/2)\n",
    "            net_rate = src_cts / cts\n",
    "            \n",
    "            #need to conver to absolute\n",
    "            x,y = int(ans['X'].mean()),int(ans['Y'].mean())\n",
    "            like = pmap[x][y] #may not probability?\n",
    "            \n",
    "            x+=args.P0\n",
    "            y+=args.P0\n",
    "            \n",
    "            #x,y = self.frame.to_absolute(x+args.shift_blobs,y+args.shift_blobs) #+10 because of cut_to_sky_df.\n",
    "            ra,dec = ds.my_wcs.all_pix2world(x,y,0)\n",
    "\n",
    "            \n",
    "            flux =  args['mean_ECF'] * (src_cts - bkg_cts_count) / args['exp_k']\n",
    "\n",
    "            src = src.append({'FLUX' : flux, 'X' : x, 'Y' : y, 'RA' : ra, 'DEC' : dec,\n",
    "                        'BLOB_PIXELS' : blob_pixels,\n",
    "                        'CTS': cts, 'BOX_CTS' : box_cts,  'SRC_CTS' : src_cts,\n",
    "                        'BKG_CTS_CORRECT' : bkg_cts_correct, 'BOX_SIZE' : box_size, \n",
    "                        'BKG_CTS_COUNT' : bkg_cts_count,\n",
    "                        'LIKE' : like, 'MEAN_EXP_TIME' : args['exp_k'], 'NET_RATE' : net_rate},\n",
    "                         ignore_index=True)\n",
    "        \n",
    "        \n",
    "        print(f'BLOBS WITH < N photons {small_blob_N}')\n",
    "        print(f'SRC LEN {len(src)}')\n",
    "              \n",
    "        #ADD ERR - just for format\n",
    "        src['SRC_CTS_ERR'] = np.zeros(len(src))\n",
    "        src['FLUX_ERR'] = np.zeros(len(src))\n",
    "        src['NET_RATE_ERR'] = np.zeros(len(src))\n",
    "        src['RA_DEC_ERR'] = np.zeros(len(src))\n",
    "        src = src.sort_values(by = 'FLUX', ascending = False)\n",
    "\n",
    "        return src\n",
    "    def boxlist0(self, cur_ans):\n",
    "        #Input: 2D numpy array data \n",
    "        #Output: list of blobs (blob - a list of points)\n",
    "        def get_blobs(data0, pmap): #data0 - centers, pmap - probability map\n",
    "            data = data0.copy()\n",
    "\n",
    "            blob,blobs = [],[]\n",
    "            sizeX, sizeY = data.shape\n",
    "\n",
    "            def get_near(x,y,data):\n",
    "                ans = []\n",
    "                for dx in [-1,0,1]:\n",
    "                    for dy in [-1,0,1]:\n",
    "                        nx,ny = x+dx,y+dy\n",
    "                        #Check if it is my center point or it's just less probable\n",
    "                        if (nx >=0 and nx < sizeX and ny>=0 and ny < sizeY) and data[nx][ny]!=2 and \\\n",
    "                            ((data[nx][ny]==1) or (pmap[x][y] >= pmap[nx][ny] >= args['min_object_p'])): #or it's just less probable\n",
    "\n",
    "                            data[nx][ny]=2\n",
    "                            ans.append((nx,ny))\n",
    "\n",
    "                if (x,y) in ans:\n",
    "                    ans.remove((x,y))\n",
    "                return ans\n",
    "\n",
    "            def array_search(x,y,data):\n",
    "                ans,cur = [],[]\n",
    "\n",
    "                if data[x][y] == 1:\n",
    "                    cur.append((x,y))\n",
    "\n",
    "                while cur!=[]:\n",
    "                    ans += cur\n",
    "                    prev = cur.copy()\n",
    "                    cur = []\n",
    "\n",
    "                    for pnt in prev:\n",
    "                        cur+=get_near(*pnt, data)\n",
    "\n",
    "                return ans \n",
    "\n",
    "            for x in range(sizeX):\n",
    "                for y in range(sizeY):\n",
    "                    if data[x][y] == 1:\n",
    "                        blob = []\n",
    "                        blob+=array_search(x,y,data) #it is appending to blob\n",
    "                        blobs.append(blob)\n",
    "                        #print('Blob',blobs)\n",
    "            return blobs #fitst method just to add initial blobs    \n",
    "\n",
    "        #------get some blobs from ans----------\n",
    "        #plt.imshow(cur_ans)\n",
    "        #plt.show()\n",
    "        \n",
    "        centers = cur_ans.copy()\n",
    "        pmap = cur_ans.copy()\n",
    "        pmap = gaussian_filter(pmap, sigma = 1)\n",
    "\n",
    "        print ('CUR MIN BLOB PIX', args['min_blob_pixels'])\n",
    "        centers = (centers == maximum_filter(centers,footprint=np.ones((9,9)))) * (pmap > args['min_blob_pixels'])\n",
    "        centers = convolve(centers, np.ones((3,3)), mode='constant', cval=0.0)\n",
    "        centers = centers.astype(int)\n",
    "\n",
    "        blobs = get_blobs(centers, pmap)\n",
    "        print('All blobs', len(blobs))\n",
    "        #cut small blobs\n",
    "        blobs = [blob for blob in blobs if len(blob) > args['min_blob_pixels']]\n",
    "        print('After min blob pixels cut', len(blobs))\n",
    "\n",
    "        #-------count noize mean for later use\n",
    "        df = self.df.copy()\n",
    "\n",
    "        def is_noize(row):\n",
    "            return pmap[int(row['X'])][int(row['Y'])] < args['noize_bound']\n",
    "\n",
    "        df['is_noize'] = df.apply(is_noize, axis = 1)\n",
    "        df = df.query('is_noize == True')\n",
    "\n",
    "        S = (pmap < args['noize_bound']).astype(int).sum() #n of noize pixels\n",
    "        noize_p = len(df) / S\n",
    "        print('current noize p',noize_p)\n",
    "\n",
    "\n",
    "        #-------convert blobs to dataframe src with all information\n",
    "        #OK, now we have some blobs. Extract center and flux from each blob know\n",
    "        src = pd.DataFrame(columns=['FLUX', 'X', 'Y', 'SRC_CTS', 'BKG_CTS'])\n",
    "\n",
    "        #for each blob we need to count number of photons in it \n",
    "        df = self.df\n",
    "        small_blob_N = 0\n",
    "        for blob in tqdm_notebook(blobs):\n",
    "            cur_blob = np.array(blob).T\n",
    "            x0,x1,y0,y1 = cur_blob[0].min(), cur_blob[0].max(), cur_blob[1].min(), cur_blob[1].max()\n",
    "            cur_df = df[df['X'].between(x0,x1) & df['Y'].between(y0,y1)]\n",
    "\n",
    "            X = cur_blob[0]\n",
    "            Y = cur_blob[1]\n",
    "            div = X / Y\n",
    "            res = X - Y\n",
    "            ans = cur_df.query('X in @X and Y in @Y and X/Y in @div')\n",
    "\n",
    "            if len(ans) < 5:\n",
    "                small_blob_N +=1\n",
    "                continue\n",
    "\n",
    "            blob_pixels = len(blob)\n",
    "            bkg_cts_count = int(noize_p * blob_pixels)\n",
    "            cts = len(ans)\n",
    "            src_cts = cts - bkg_cts_count #len(ans[ans['SRC_ID']!=-1])\n",
    "            bkg_cts_correct = len(ans[ans['SRC_ID']==-1]) #need to estimate from image\n",
    "\n",
    "            box_cts = 0 #len(cur_df)\n",
    "            box_size = int((x1-x0+y1-y0+2)/2)\n",
    "            net_rate = src_cts / cts\n",
    "            \n",
    "            #need to conver to absolute\n",
    "            x,y = int(ans['X'].mean()),int(ans['Y'].mean())\n",
    "            like = pmap[x][y] #may not probability?\n",
    "            \n",
    "            x,y = x+10,y+10 #+10 because of cut_to_sky_df.\n",
    "            ra,dec = ds.my_wcs.all_pix2world(x,y,0)\n",
    "\n",
    "            \n",
    "            flux =  args['mean_ECF'] * (src_cts - bkg_cts_count) / args['exp_k']\n",
    "\n",
    "            src = src.append({'FLUX' : flux, 'X' : x, 'Y' : y, 'RA' : ra, 'DEC' : dec,\n",
    "                        'BLOB_PIXELS' : blob_pixels,\n",
    "                        'CTS': cts, 'BOX_CTS' : box_cts,  'SRC_CTS' : src_cts,\n",
    "                        'BKG_CTS_CORRECT' : bkg_cts_correct, 'BOX_SIZE' : box_size, \n",
    "                        'BKG_CTS_COUNT' : bkg_cts_count,\n",
    "                        'LIKE' : like, 'MEAN_EXP_TIME' : args['exp_k'], 'NET_RATE' : net_rate},\n",
    "                         ignore_index=True)\n",
    "            \n",
    "        print(f'BLOBS WITH < 5 photons {small_blob_N}')\n",
    "\n",
    "        #ADD ERR - just for format\n",
    "        src['SRC_CTS_ERR'] = np.zeros(len(src))\n",
    "        src['FLUX_ERR'] = np.zeros(len(src))\n",
    "        src['NET_RATE_ERR'] = np.zeros(len(src))\n",
    "        src['RA_DEC_ERR'] = np.zeros(len(src))\n",
    "        src = src.sort_values(by = 'FLUX', ascending = False)\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "code_folding": [
     3,
     44,
     74,
     81,
     91,
     99,
     130,
     136,
     154,
     169,
     173
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###################Sample##################################\n",
    "#  A Class for one sample (image) processing. Gets all nessesary data for NN\n",
    "############################################################    \n",
    "class Sample():\n",
    "    def __init__(self, df=None, simput=None, frame=None, n = None, frame_i = None, mode = 'train'): #df + simput\n",
    "        self.df = df\n",
    "        self.simput = simput\n",
    "        self.frame = frame\n",
    "        self.n = n\n",
    "        self.frame_i = frame_i\n",
    "        self.kde_kernel = 'gaussian'\n",
    "        self.flux_class_list = [] #in order of kde\n",
    "        self.bad_KDE_src = []\n",
    "        \n",
    "        self.thres_list = args['unet_thres_list']\n",
    "        self.thres_data = {}\n",
    "        self.mode = mode\n",
    "        #self.stat = pd.read_excel('unet_v1_stat.xlsx')\n",
    "        #self.stat = self.stat.iloc[0:0]        \n",
    "        \n",
    "    def prepare(self):\n",
    "        #Croping by frame\n",
    "        self.df = self.df.reset_index()\n",
    "        self.df, self.simput = self.frame.crop_data(self.df, self.simput)\n",
    "        \n",
    "        \n",
    "        self.get_bin_flux()\n",
    "        self.n_obj = len(self.simput)\n",
    "        \n",
    "        \n",
    "        self.get_image_matrix() \n",
    "        \n",
    "        \n",
    "        self.prepare_images()\n",
    "        \n",
    "        self.old_simput = self.simput.copy()\n",
    "        print('wwww', len(self.simput))\n",
    "        \n",
    "        if self.mode != 'test':\n",
    "            self.image_KDE()\n",
    "        #self.draw_image(draw_mode = '126')\n",
    "\n",
    "        self.simput = self.old_simput\n",
    "    #Train Matrix\n",
    "    def get_image_matrix(self):\n",
    "        channels_N = args['channels_N']\n",
    "        mat = np.zeros((self.frame.sizeX,self.frame.sizeY,channels_N))\n",
    "\n",
    "        if args['full_energy_channel']:\n",
    "            channels_N -= 1 #Free one channel for full energy\n",
    "\n",
    "\n",
    "        #chan_size = args['max_PHA'] / channels_N \n",
    "\n",
    "        #self.df = self.df.reset_index()\n",
    "\n",
    "        for i in range(len(self.df)):\n",
    "            row = self.df.iloc[i]\n",
    "            x = int(row['X'])\n",
    "            y = int(row['Y'])\n",
    "            cur_chan = int(row['PHOTON_TYPE']) - 1 #-1 because we have [1,32] values\n",
    "            #cur_chan = row['PHA'] # min( int(row['PHA'] / chan_size), channels_N-1) \n",
    "            #mat[x][y][chan] += exp[x][y] #when i'll get the exp map\n",
    "            mat[x][y][cur_chan] += 1\n",
    "\n",
    "            if args['full_energy_channel']:\n",
    "                mat[x][y][channels_N] += row['SIGNAL'] #just add signal to last channel\n",
    "\n",
    "        self.mat = mat\n",
    "        return \n",
    "\n",
    "    ############################################################\n",
    "    #  Box + mask work\n",
    "    ############################################################\n",
    "    def normalize_point(self, x,y):\n",
    "        x = min(self.frame.sizeX-1, x)\n",
    "        y = min(self.frame.sizeY-1, y)\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "\n",
    "        return [int(x),int(y)]\n",
    "    def has_neighbours(self, pixel_mask, x, y): #Check if >1 source are neigbours in this point\n",
    "        #Work with borders\n",
    "        zone = pixel_mask[max(0,x-1):min(self.frame.sizeX-1,x+1)+1, max(0,y-1):min(self.frame.sizeY-1, y+1)+1]\n",
    "        src_li = set()\n",
    "        for i in range(zone.shape[0]):\n",
    "            for j in range(zone.shape[1]):\n",
    "                if zone[i][j].src_id != None:\n",
    "                    src_li.add(zone[i][j].src_id)\n",
    "\n",
    "        return len(src_li) > 1\n",
    "    def object_KDE(self, x, y, bandwidth = 3, xbins=100j, ybins=100j, **kwargs): \n",
    "        bandwidth = args['KDE_bandwidth']\n",
    "        #bandwidth = 1.06 * np.std(x) * len(x) ** (-0.2)\n",
    "\n",
    "        xy_train  = np.vstack([y, x]).T\n",
    "        kde_skl = KernelDensity(bandwidth=bandwidth, kernel = self.kde_kernel, **kwargs)\n",
    "        kde_skl.fit(xy_train)\n",
    "        return kde_skl \n",
    "    def object_mask_pixels(self, X,Y, search_area = 100):\n",
    "        #A bit sheety, but works. Normalizing data\n",
    "        meanX, meanY = int(np.median(X)), int(np.median(Y))\n",
    "        X = [x - meanX for x in X]\n",
    "        Y = [y - meanY for y in Y]\n",
    "\n",
    "        #Apply KDE\n",
    "        kde = self.object_KDE(X, Y)\n",
    "\n",
    "        #Get regions with p > threshold (A bit sheety)\n",
    "        mask, pnt = [], []\n",
    "        #for x in range(-search_area, search_area):\n",
    "        #    for y in range(-search_area, search_area):\n",
    "        #        pnt.append([x,y])\n",
    "        \n",
    "        r = list(range(-search_area, search_area))\n",
    "        pnt = list(itertools.product(*[r, r]))\n",
    "\n",
    "        mask = np.exp(kde.score_samples(pnt))\n",
    "        mask = mask.reshape((len(mask),1))\n",
    "        \n",
    "        #print(mask)\n",
    "\n",
    "        pnt = np.array(pnt)\n",
    "        pnt = np.concatenate( (pnt,mask) , axis =1)\n",
    "        #print('KDE', pnt.shape)\n",
    "        pnt = pnt [list(np.where(mask > args['p_mask'])), ][0]\n",
    "        #Denormalize\n",
    "        pnt = [self.normalize_point(value[0]+meanX,value[1]+meanY) + [value[2]] for value in pnt]\n",
    "\n",
    "        return pnt\n",
    "    def n_obj_zone(self, delta,pixel_mask,x,y, no_bg = True):\n",
    "        zone = pixel_mask[max(0,x-delta):min(self.frame.sizeX-1,x+delta)+1, max(0,y-delta):min(self.frame.sizeY-1, y+delta)+1]\n",
    "        zone = set([elem.src_id for elem in zone.flatten()])\n",
    "        if no_bg and None in zone:\n",
    "            zone.remove(None)\n",
    "        return len(zone) \n",
    "    def get_dist_to_closest(self, pixel_mask,x,y):\n",
    "\n",
    "        if self.n_obj_zone(9,pixel_mask,x,y) < 2:\n",
    "            return 9,9\n",
    "\n",
    "        #Work with borders\n",
    "        delta = 1\n",
    "        d1=d2=9\n",
    "        for delta in range(1,10):\n",
    "            n = self.n_obj_zone(delta,pixel_mask,x,y)\n",
    "            if n == 1:\n",
    "                d1 = min(d1, delta)\n",
    "            elif n>=2:\n",
    "                d1 = min(d1, delta)\n",
    "                d2 = min(d2, delta)\n",
    "                return d1,d2\n",
    "\n",
    "        return d1,d2        \n",
    "    def get_box(self, pnts0, src_id):\n",
    "        #pnts[i] : x,y,prob\n",
    "        pnts = np.array(pnts0).T\n",
    "        xmax,xmin,ymax,ymin = pnts[0,:].max(),pnts[0,:].min(),pnts[1,:].max(),pnts[1,:].min()\n",
    "        box_size = max(xmax-xmin, ymax-ymin)\n",
    "        x0 = int(xmin + (xmax-xmin)/2)\n",
    "        y0 = int(ymin + (ymax-ymin)/2) \n",
    "        try:\n",
    "            log_bin_flux = int(list(self.simput[self.simput['SRC_ID']==int(src_id)]['FLUX_CLASS'])[0])\n",
    "        except:\n",
    "            print('MEGA ERROR',src_id, (list(self.simput[self.simput['SRC_ID']==int(src_id)]['FLUX_CLASS'])[0])) \n",
    "            log_bin_flux = 5\n",
    "        \n",
    "        self.flux_class_list.append(log_bin_flux) #\n",
    "        return [x0,y0,box_size,log_bin_flux]\n",
    "    def remove_by_src_id(self, bad_list):\n",
    "        self.df = self.df[~self.df['SRC_ID'].isin(bad_list)]\n",
    "        self.simput = self.simput[~self.simput['SRC_ID'].isin(bad_list)]\n",
    "        self.n_obj = len(self.simput)   \n",
    "    def image_KDE(self):\n",
    "        #Сделать 2D list. В нём объекты - Pixel (p, src, color). Дальше по этой карте рисовать чисто маску.\n",
    "        #For images\n",
    "        pic = self.photon_pic.copy()\n",
    "\n",
    "        gt = np.zeros((self.frame.sizeX, self.frame.sizeY)) #ground truth\n",
    "        weight_mask = np.ones((self.frame.sizeX, self.frame.sizeY)) #error mask\n",
    "\n",
    "        #Prepare data\n",
    "        SRC_X = {}\n",
    "        SRC_Y = {}\n",
    "\n",
    "        #Get all X,Y coordinated for each source to dict.\n",
    "        for i in range(len(self.df)):\n",
    "            row = self.df.iloc[i]\n",
    "            src,x,y = row['SRC_ID'],row['X'],row['Y']\n",
    "            if src == -1:\n",
    "                continue\n",
    "\n",
    "            if src in SRC_X.keys():\n",
    "                    SRC_X[src].append(x)\n",
    "                    SRC_Y[src].append(y)\n",
    "            else:\n",
    "                SRC_X[src] = [x]\n",
    "                SRC_Y[src] = [y]\n",
    "                \n",
    "        self.SRC_X = SRC_X\n",
    "        self.SRC_Y = SRC_Y\n",
    "\n",
    "        #Fill KDE to matrix\n",
    "        pixel_mask = np.array([[Pixel() for j in range(self.frame.sizeY)] for i in range(self.frame.sizeX)])\n",
    "        \n",
    "        #per source binary mask for F-CNN\n",
    "        #binary_object_mask = np.zeros([self.frame.sizeX, self.frame.sizeY, len(SRC_X.keys())], dtype=np.uint8) \n",
    "        boxes = [] #box[i] = [X0,Y0,WIDTH]\n",
    "\n",
    "        for i, src_id in enumerate(SRC_X.keys()):\n",
    "            X = np.array(SRC_X[src_id]) #Эм, убрал сортировку и заработало.Не понимаю\n",
    "            Y = np.array(SRC_Y[src_id])\n",
    "\n",
    "            #All pixels with > thres probability\n",
    "            pnts = self.object_mask_pixels (X,Y)\n",
    "            \n",
    "            if len(pnts) == 0: #BAD SOURCE\n",
    "                self.bad_KDE_src.append(src_id)\n",
    "                continue\n",
    "\n",
    "            boxes.append(self.get_box(pnts, src_id))\n",
    "\n",
    "\n",
    "            #Modify pixel_mask for each source. Fill with max probability or red if it's border\n",
    "            for pnt in pnts:   \n",
    "                x,y,newP = pnt[0], pnt[1], pnt[2]\n",
    "\n",
    "                if pixel_mask[x][y].p < newP: #<p\n",
    "                    pixel_mask[x][y].p = newP\n",
    "                    pixel_mask[x][y].src_id = src_id\n",
    "                   \n",
    "                    #For images\n",
    "                    pixel_mask[x][y].src_color = self.src_color[src_id]\n",
    "                    pic[x,y,:] = self.src_color[src_id]\n",
    "                    \n",
    "                    gt[x][y] = 1\n",
    "                    weight_mask[x][y] = args['object_weight']\n",
    "                    \n",
    "                    #binary_object_mask[x,y,i] = 1\n",
    "                    \n",
    "        #If it is a border of two objects - draw red\n",
    "        if args['high_border_weight']:\n",
    "            for x in range(self.frame.sizeX):\n",
    "                for y in range(self.frame.sizeY):\n",
    "                    if self.has_neighbours(pixel_mask, x, y):\n",
    "\n",
    "                        pixel_mask[x][y].src_color = (255,255,255)\n",
    "                        pic[x,y,:] = (255,255,255)\n",
    "\n",
    "                        gt[x][y] = 0 #remove borders.\n",
    "                        weight_mask[x][y] = 10 #no errors in borders!!!\n",
    "\n",
    "        #New borders work - Unet weights          \n",
    "        if args['border_KDE']:\n",
    "            #Find border points\n",
    "            r = 10\n",
    "            borders = set()\n",
    "            for x in range(self.frame.sizeX):\n",
    "                for y in range(self.frame.sizeY):\n",
    "                    #if it is border object pixel with another object in r radius\n",
    "                    if gt[x][y] == 1 and self.n_obj_zone(1,pixel_mask,x,y, no_bg=False) > 1 and self.n_obj_zone(r,pixel_mask,x,y ) > 1:\n",
    "                            borders |= set(list(product(list(range(max(0,x-r),min(x+r, self.frame.sizeX))), \n",
    "                                                        list(range(max(0,y-r),min(y+r, self.frame.sizeY))))))\n",
    "\n",
    "\n",
    "            #Create weights for border points\n",
    "            #ans = []\n",
    "            for pnt in borders:\n",
    "                x,y = pnt\n",
    "\n",
    "                #Settings for mask\n",
    "                w0 = 10\n",
    "                sigma = 4\n",
    "\n",
    "                #Unet weight formula\n",
    "                if gt[x][y] == 0: # a border or just no object\n",
    "                    d1,d2 = self.get_dist_to_closest(pixel_mask, x, y)\n",
    "                    weight_mask[x][y] = max(int(w0 * math.exp(- (d1+d1)**2 / (2*sigma**2))),1)\n",
    "                    #ans.append(weight_mask[x][y])\n",
    "            #print(ans)\n",
    "        \n",
    "        #Cut binary mask lenght from object with empty KDE\n",
    "        #binary_object_mask = binary_object_mask[:,:,:len(SRC_X.keys()) - len(self.bad_KDE_src)]\n",
    "        #Remove such objects from df and simput\n",
    "        self.remove_by_src_id(self.bad_KDE_src)\n",
    "        \n",
    "        self.KDE_pic = pic\n",
    "        self.gt = gt \n",
    "        self.wm = weight_mask \n",
    "        #self.boxes = boxes\n",
    "        #self.binary_object_mask = binary_object_mask\n",
    "        return\n",
    "    \n",
    "    ############################################################\n",
    "    #  Painting dataset\n",
    "    ############################################################\n",
    "    @staticmethod\n",
    "    def get_distinct_colors(n):\n",
    "        def HSVToRGB(h, s, v):\n",
    "            (r, g, b) = colorsys.hsv_to_rgb(h, s, v)\n",
    "            return (int(255*r), int(255*g), int(255*b))\n",
    "\n",
    "        huePartition = 1.0 / (n + 1)\n",
    "        return (HSVToRGB(huePartition * value, 1, 0.5) for value in range(0, n))  #Generating N different colors\n",
    "    def get_bin_flux(self):\n",
    "        min_flux = abs(self.simput['LOG_FLUX'].max())\n",
    "        ran = abs(self.simput['LOG_FLUX'].max() - self.simput['LOG_FLUX'].min())\n",
    "        n = 10\n",
    "        def f(value):\n",
    "            return n - int((np.float(abs(value)) - np.float(min_flux)) / ran * n)\n",
    "        self.simput['LOG_FLUX_BIN']= self.simput['LOG_FLUX'].apply(f)\n",
    "        return\n",
    "    def prepare_images(self): #prepare mat with photonos and color_src\n",
    "        #Sampling not need for this data\n",
    "        all_src = list(self.df['SRC_ID'].unique())\n",
    "        cur_src = all_src\n",
    "\n",
    "\n",
    "\n",
    "        #Set color to each source\n",
    "        colorN = args['n_src']\n",
    "        colors = list(Sample.get_distinct_colors(colorN))\n",
    "        src_color = {}\n",
    "        for key in list(set(self.df['SRC_ID'])):\n",
    "            src_color[key] = colors[random.randint(0,colorN-1)]\n",
    "\n",
    "        #Create image matrix\n",
    "        mat = np.zeros(shape=(self.frame.sizeX, self.frame.sizeY, 3))\n",
    "        mat_wht = np.zeros(shape=(self.frame.sizeX, self.frame.sizeY, 3))\n",
    "\n",
    "        #Fill it with data from cur_df (photons)\n",
    "        for i in range(len(self.df)):\n",
    "            mat[self.df['X'].iloc[i], self.df['Y'].iloc[i]] =  src_color[self.df['SRC_ID'].iloc[i]]\n",
    "            mat_wht[self.df['X'].iloc[i], self.df['Y'].iloc[i]] = (125,125,125)\n",
    "\n",
    "        #try convolution to enlarge objects\n",
    "        kernel = np.ones((3,3))\n",
    "        mat = cv2.filter2D(mat, cv2.CV_64F, kernel)   \n",
    "        \n",
    "        self.photon_pic = mat\n",
    "        self.src_color = src_color\n",
    "    def paint_matrix(self,mats, size = 50):\n",
    "        #print (mats.shape)\n",
    "        fig=plt.figure(figsize=(len(mats)*size, size))\n",
    "        columns = len(mats)\n",
    "\n",
    "        for i in range(1, columns+1):\n",
    "            fig.add_subplot(1, columns, i)\n",
    "            imshow(Image.fromarray(np.uint8(mats[i-1])) , interpolation='nearest')\n",
    "            plt.grid = False\n",
    "            #plt.axis('on')\n",
    "        #plt.colorbar()\n",
    "        plt.show() #matrix - list of numpy arrays.\n",
    "    def save_matrix(self,mats,size = 50, path = '1.png'):\n",
    "        mpl.rcParams['figure.dpi']= 300\n",
    "        fig=plt.figure(figsize=(len(mats)*6, 6))\n",
    "        columns = len(mats)\n",
    "\n",
    "        for i in range(1, columns+1):\n",
    "            fig.add_subplot(1, columns, i)\n",
    "            plt.imshow(mats[i-1], interpolation='nearest')\n",
    "            plt.grid(False)\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.savefig(path, bbox_inches='tight')\n",
    "        mpl.rcParams['figure.dpi']= 80\n",
    "    def draw_image (self,draw_mode = '1', **kwargs):\n",
    "        #------------------------VARIOUS IMAGES MODES-------------------\n",
    "        images = []\n",
    "\n",
    "        #Draw just photons\n",
    "        if '1' in draw_mode:\n",
    "            images.append(self.photon_pic)\n",
    "\n",
    "        #Draw KDE    \n",
    "        if '2' in draw_mode: \n",
    "            images.append(self.KDE_pic)\n",
    "        \n",
    "        #Draw GT\n",
    "        if '3' in draw_mode: \n",
    "            images.append(self.gt)\n",
    "        \n",
    "        #Draw weights\n",
    "        if '4' in draw_mode: \n",
    "            images.append(self.wm)\n",
    "\n",
    "        #Draw photons + centers\n",
    "        if '5' in draw_mode:\n",
    "            mat = self.photon_pic.copy()\n",
    "            for i in range(len(self.simput)): #check for each source\n",
    "                bin_flux = 0\n",
    "                if 'LOG_FLUX_BIN' in self.simput.columns:\n",
    "                    bin_flux = int(self.simput.iloc[i]['LOG_FLUX_BIN'])\n",
    "\n",
    "                sX,sY = int(self.simput.iloc[i]['X']),int(self.simput.iloc[i]['Y'])\n",
    "\n",
    "                #red square\n",
    "                d = 5 + 2 * bin_flux\n",
    "                tmp = mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)]\n",
    "                for i in range(tmp.shape[0]):\n",
    "                    for j in range(tmp.shape[1]):\n",
    "                        #if i==j or i+j ==d\n",
    "                        if i <2 or j<2 or i >= tmp.shape[0]-2 or j >= tmp.shape[1]-2:\n",
    "                            tmp[i][j] = (255,255,255)\n",
    "\n",
    "                mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)] = tmp\n",
    "\n",
    "            images.append(mat)\n",
    "        \n",
    "        #Draw photons + gt boxes\n",
    "        if '6' in draw_mode:\n",
    "            mat = self.KDE_pic.copy()\n",
    "            for box in self.boxes:\n",
    "                w = int(box[2]/2)\n",
    "                cv2.rectangle(mat,(box[1]-w,box[0]-w),(box[1]+w,box[0]+w),(255,255,255),1)\n",
    "            images.append(mat)\n",
    "            \n",
    "        #Draw predicted image + centers\n",
    "        if '7' in draw_mode:\n",
    "            mat = np.dstack([self.ans.copy() * 255 / self.ans.max()] * 3)\n",
    "            #mat[:,:,0] = self.ans.copy()\n",
    "            \n",
    "            for i in range(len(self.simput)): #check for each source\n",
    "                bin_flux = 0\n",
    "                if 'LOG_FLUX_BIN' in self.simput.columns:\n",
    "                    bin_flux = int(self.simput.iloc[i]['LOG_FLUX_BIN'])\n",
    "\n",
    "                sX,sY = int(self.simput.iloc[i]['X']),int(self.simput.iloc[i]['Y'])\n",
    "\n",
    "                #red square\n",
    "                d = 5 + 2 * bin_flux\n",
    "                tmp = mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)]\n",
    "                for i in range(tmp.shape[0]):\n",
    "                    for j in range(tmp.shape[1]):\n",
    "                        #if i==j or i+j ==d\n",
    "                        if i <2 or j<2 or i >= tmp.shape[0]-2 or j >= tmp.shape[1]-2:\n",
    "                            tmp[i][j] = (255,0,0)\n",
    "\n",
    "                mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)] = tmp\n",
    "\n",
    "            images.append(mat)\n",
    "        \n",
    "        if '8' in draw_mode:\n",
    "            mat = kwargs['im']\n",
    "            print(mat.max())\n",
    "            #mat = np.dstack([mat * 255 / mat.max()] * 3) \n",
    "            #mat = mat * 255 / mat.max()\n",
    "            print(mat.max())\n",
    "            \n",
    "            for i in range(len(self.simput)): #check for each source\n",
    "                bin_flux = 0\n",
    "                if 'LOG_FLUX_BIN' in self.simput.columns:\n",
    "                    bin_flux = int(self.simput.iloc[i]['LOG_FLUX_BIN'])\n",
    "\n",
    "                sX,sY = int(self.simput.iloc[i]['X']),int(self.simput.iloc[i]['Y'])\n",
    "\n",
    "                #red square\n",
    "                d = 5 + 2 * bin_flux\n",
    "                tmp = mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)]\n",
    "                for i in range(tmp.shape[0]):\n",
    "                    for j in range(tmp.shape[1]):\n",
    "                        #if i==j or i+j ==d\n",
    "                        if i <2 or j<2 or i >= tmp.shape[0]-2 or j >= tmp.shape[1]-2:\n",
    "                            tmp[i][j] = (255,0,0)\n",
    "                            if tmp[5][5][0] != 0:\n",
    "                                tmp[i][j] = (0,255,0)\n",
    "#                         if i==j or i+j==2*d-2:\n",
    "#                             tmp[i][j] = (255,0,0)\n",
    "\n",
    "                mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)] = tmp\n",
    "\n",
    "            images.append(mat)      \n",
    "\n",
    "        if '9' in draw_mode:\n",
    "            found = kwargs['found']\n",
    "            mat = np.dstack([self.ans.copy() * 255 / self.ans.max()] * 3)\n",
    "            \n",
    "            #mat[:,:,0] = self.ans.copy()\n",
    "            \n",
    "            for i in range(len(self.simput)): #check for each source\n",
    "                bin_flux = 0\n",
    "                if 'LOG_FLUX_BIN' in self.simput.columns:\n",
    "                    bin_flux = int(self.simput.iloc[i]['LOG_FLUX_BIN'])\n",
    "\n",
    "                sX,sY = int(self.simput.iloc[i]['X']),int(self.simput.iloc[i]['Y'])\n",
    "\n",
    "                #red square\n",
    "                d = 5 + 2 * bin_flux\n",
    "                tmp = mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)]\n",
    "                for i in range(tmp.shape[0]):\n",
    "                    for j in range(tmp.shape[1]):\n",
    "                        #if i==j or i+j ==d\n",
    "                        if i <2 or j<2 or i >= tmp.shape[0]-2 or j >= tmp.shape[1]-2:\n",
    "                            tmp[i][j] = (0,255,0)\n",
    "\n",
    "                mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)] = tmp\n",
    "                \n",
    "            for i in range(len(found)): #check for each source\n",
    "                sX,sY = int(found.iloc[i]['X']),int(found.iloc[i]['Y'])\n",
    "\n",
    "                #red cross\n",
    "                d = 5\n",
    "                tmp = mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)]\n",
    "                for i in range(tmp.shape[0]):\n",
    "                    for j in range(tmp.shape[1]):\n",
    "                        if i==j or i+j==2*d-2:\n",
    "                            tmp[i][j] = (255,0,0)\n",
    "                mat[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)] = tmp\n",
    "\n",
    "            images.append(mat)\n",
    "        \n",
    "            \n",
    "\n",
    "        #c = np.concatenate(images, axis=1)\n",
    "        #paint_and_save(c, '0.jpg')\n",
    "        print('Painting')\n",
    "        self.paint_matrix(images)\n",
    "        #self.save_matrix(images)\n",
    "        #self.full_image = images\n",
    "        return images\n",
    "\n",
    "    ############################################################\n",
    "    #  Getting class output in different formats\n",
    "    ############################################################\n",
    "    def generate_data(self, mode):\n",
    "        if mode=='train':\n",
    "            dct = {'image': self.mat[np.newaxis, ...], 'weights': self.wm[np.newaxis, ...]}, \\\n",
    "                  {'output': self.gt[np.newaxis,...,np.newaxis]}\n",
    "            return dct\n",
    "        elif mode == 'test':\n",
    "            dct = {'image': self.mat[np.newaxis, ...], 'weights': np.zeros(shape=(1, 512, 512)) }\n",
    "            return dct\n",
    "        elif mode == 'ROC':\n",
    "            dct = {'image': self.mat[np.newaxis, ...], 'weights': self.wm[np.newaxis, ...]}\n",
    "            return self.df, self.simput, dct\n",
    "       \n",
    "    ############################################################\n",
    "    #  File work\n",
    "    ############################################################\n",
    "    def save_to_file(self,file='ds_test.npy'):\n",
    "        tmp = self.__dict__.copy()\n",
    "        del tmp['mat']\n",
    "        np.save(file, tmp) #save without mat, it's heavy\n",
    "    def load_from_file(self, file): #init from dictionary\n",
    "        ds_dict = np.load(file)[()]\n",
    "        for k, v in ds_dict.items():\n",
    "            setattr(self, k, v)        \n",
    "        if not('mat' in self.__dict__): #load it back\n",
    "            self.get_image_matrix()        \n",
    "            \n",
    "        #modify weight mask 1-1-10 scheme    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
    "        self.wm[self.wm != 1] = args['object_weight']\n",
    "    def get_self_size(self): #get size of all my fiels\n",
    "        size_dict = {}\n",
    "        for key,value in self.__dict__.items():\n",
    "            if isinstance(value, pd.core.frame.DataFrame):\n",
    "                size_dict[key] = value.memory_usage().sum()\n",
    "            if isinstance(value, np.ndarray):\n",
    "                size_dict[key] = value.nbytes\n",
    "        print(size_dict)\n",
    "        \n",
    "    ############################################################\n",
    "    #  Prediction and data processing\n",
    "    ############################################################\n",
    "    def predict(self, model):\n",
    "        data = self.generate_data(mode = 'test')\n",
    "        self.ans = model.predict_on_batch(data)[0,:,:,0]        \n",
    "    def get_stat(self,model, model_path = 'unet'):\n",
    "        data = self.generate_data(mode = 'test')\n",
    "        self.ans = model.predict_on_batch(data)[0,:,:,0]\n",
    "        #ans = ans.T #We transpose it in all previous methods\n",
    "        \n",
    "        print('STAT',len(self.stat))\n",
    "        \n",
    "        min_flux = args['conf_limit'] #works only for conf limit now\n",
    "        self.get_thres_data_net()\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            name = model_path.replace('.','/').split('/')[1] #take it from model path\n",
    "        except:\n",
    "            name = 'unet_unparsed'\n",
    "        print ('name', name)\n",
    "        \n",
    "        self.add_stat(name, min_flux)#stat is updated \n",
    "    def update_stat(self,mode, min_flux): #update stat from current thres_data\n",
    "        for thres, data in self.thres_data.items():\n",
    "            d = {'mode' : mode,\n",
    "                 'min_flux' : min_flux,\n",
    "                 'thres': thres, \n",
    "                 'TP' : data['TP'], \n",
    "                 'FP' : data['FP'], \n",
    "                 'FN' : data['FN'], \n",
    "                 'CP' : data['CP'], \n",
    "                 'PCP' : data['PCP'],\n",
    "                 'N' : data['N'],\n",
    "                 'object_pixels' : data['object_pixels'],\n",
    "                 'all_ph' : data['all_ph'], \n",
    "                 'found_ph' : data['found_ph'],\n",
    "                 'prec' : 0, \n",
    "                 'rec' : 0}\n",
    "            new = pd.DataFrame.from_dict(d,orient='index').T\n",
    "            self.stat = pd.concat([self.stat,new],\n",
    "                             axis = 0, ignore_index = True)\n",
    "        return \n",
    "    def add_stat(self,mode, min_flux): #update stat from current thres_data\n",
    "        print('STAT',len(self.stat))\n",
    "        for thres, data in self.thres_data.items():\n",
    "            #add new values to stat\n",
    "            if len(self.stat) == 0 or \\\n",
    "               len(self.stat[(self.stat.thres==thres) & \\\n",
    "                             (self.stat['mode']=='unet') & \\\n",
    "                             (self.stat.min_flux==min_flux)]) == 0:     \n",
    "                self.update_stat(mode, min_flux)\n",
    "            #update current values\n",
    "            else:\n",
    "                self.stat.loc[(self.stat.thres==thres) & \n",
    "                         (self.stat.mode=='unet') &\n",
    "                         (self.stat.min_flux==min_flux), ['TP','FP','FN','CP','PCP', 'object_pixels', 'N', 'all_ph', 'found_ph']] += [data[x] for x in ['TP','FP','FN','CP','PCP','object_pixels', 'N', 'all_ph', 'found_ph']]\n",
    "        return \n",
    "\n",
    "    #Get metrics for all thresholds for one file. We just vary thresholds here\n",
    "    def get_thres_data_net (self):\n",
    "        self.thres_images = []\n",
    "        print('THres',args['unet_thres_list'])\n",
    "        for thres in args['unet_thres_list']: \n",
    "            print ('Current Threshold', thres)\n",
    "\n",
    "            #Some prediction post processing\n",
    "            #-----------------------------------------\n",
    "            cur_ans = (self.ans > thres).astype(int) #Здесь просто округляем\n",
    "            print(cur_ans.sum())\n",
    "            #cut out small blobs\n",
    "            cur_ans = self.cut_small_blobs(cur_ans)\n",
    "\n",
    "            if args['gauss_output']:\n",
    "                #gauss a bit\n",
    "                kernel_size = args['gauss_size']\n",
    "                kernel = np.ones((kernel_size,kernel_size))\n",
    "                cur_ans = convolution2d(cur_ans, kernel) \n",
    "                cur_ans = (cur_ans >= 1).astype(int)\n",
    "\n",
    "            tp,fp,fn,cp,pcp,precision,recall,object_pixels,obj = self.tpr_fpr(cur_ans, paint_squares = True)\n",
    "\n",
    "            #get objects count fraction\n",
    "            all_ph = len(self.df[self.df['SRC_ID']!=-1])\n",
    "            self.df['found'] = self.df.apply(lambda row: (cur_ans[int(row['X'])][int(row['Y'])] == 1).astype(int), axis = 1)\n",
    "            found_ph = self.df[self.df['SRC_ID']!=-1]['found'].sum()\n",
    "\n",
    "            #draw a matrix with images\n",
    "            if random.random() < args['paint_random']: # paint_random:\n",
    "                #plt.imshow(cur_ans)\n",
    "                #plt.show()\n",
    "#               ph = draw_image(draw_mode = '023')\n",
    "#               ph.append(obj)\n",
    "                self.paint_matrix([obj])\n",
    "\n",
    "            self.update_thres(thres, tp, fp, fn, cp, pcp, object_pixels, all_ph, found_ph)\n",
    "            self.thres_images.append(obj)\n",
    "\n",
    "        return \n",
    "    def update_thres(self, thres, tp, fp, fn, cp, pcp, object_pixels, all_ph, found_ph):    \n",
    "        if thres not in self.thres_data:\n",
    "            self.thres_data.setdefault(thres, {'TP':0,'FP':0,'FN':0,'CP':0,'PCP':0, 'object_pixels':0, 'N':0, 'all_ph' : 0, 'found_ph' : 0})\n",
    "\n",
    "        self.thres_data[thres]['TP']  += tp\n",
    "        self.thres_data[thres]['FP']  += fp\n",
    "        self.thres_data[thres]['FN']  += fn\n",
    "        self.thres_data[thres]['CP']  += cp\n",
    "        self.thres_data[thres]['PCP'] += pcp\n",
    "        self.thres_data[thres]['object_pixels'] += object_pixels\n",
    "        self.thres_data[thres]['N'] += 1\n",
    "        self.thres_data[thres]['object_ratio'] = self.thres_data[thres]['object_pixels'] / (self.thres_data[thres]['N'] * self.frame.sizeX**2)\n",
    "        self.thres_data[thres]['all_ph'] += all_ph\n",
    "        self.thres_data[thres]['found_ph'] += found_ph\n",
    "        return \n",
    "    #Get metrics for one threshold and draw image\n",
    "    def tpr_fpr (self, pred, paint_squares = True, kernel_size = 7): #transforms pred matrix to 0/1 according to thres, counts found\n",
    "        #some structures\n",
    "        found = pred.copy()\n",
    "        obj = np.repeat(found[:,:,np.newaxis] * 255, 3, axis=2)\n",
    "\n",
    "        TP = 0\n",
    "\n",
    "        for i in range(len(self.simput)): #check for each source\n",
    "            sX,sY,src,flux,flux_bin = [int(value) for value in self.simput.iloc[i][['X','Y','SRC_ID','FLUX','LOG_FLUX_BIN']].tolist()]\n",
    "\n",
    "            if src == -1:\n",
    "                continue\n",
    "\n",
    "            #Set green color if found, red if not\n",
    "            color = (255,0,0)\n",
    "            if pred[sX][sY] == 1: # or near_source(pred, sY, sX): #source found!!!\n",
    "                found = self.set_found_object(found, sX, sY)\n",
    "                color = (0,255,0)\n",
    "\n",
    "                TP+=1\n",
    "\n",
    "            #Add object squares to image\n",
    "            if paint_squares:\n",
    "                #red square\n",
    "                d = 5 + 2*flux_bin\n",
    "                #tmp = np.ones(obj[max(0,sX-d):min(image.sizeX,sX+d),max(0,sY-d):min(image.sizeY,sY+d)].shape)\n",
    "                tmp = obj[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)].copy()\n",
    "                for i in range(tmp.shape[0]):\n",
    "                    for j in range(tmp.shape[1]):\n",
    "                        #if i==j or i+j ==d\n",
    "                        if i <2 or j<2 or i >= tmp.shape[0]-2 or j >= tmp.shape[1]-2:\n",
    "                            tmp[i][j] = color\n",
    "\n",
    "                obj[max(0,sX-d):min(self.frame.sizeX,sX+d),max(0,sY-d):min(self.frame.sizeY,sY+d)] = tmp.copy()\n",
    "\n",
    "\n",
    "        FN = len(self.simput) - TP #not found objects\n",
    "        CP = len(self.simput) #all true objects\n",
    "        FP = len(self.get_centers(found)) #FP - all objects that are left\n",
    "        PCP = TP + FP #Just all found objects\n",
    "\n",
    "        precision = recall = 0\n",
    "        if PCP !=0:\n",
    "            precision = TP / PCP\n",
    "        if CP != 0:\n",
    "            recall = TP / CP\n",
    "\n",
    "        object_pixels = sum(sum(pred)) \n",
    "\n",
    "        return TP, FP, FN,CP,PCP,precision,recall,object_pixels, obj #return all metrics for cur thres for statistics\n",
    "    #Input: 2D numpy array data, point (x,y) \n",
    "    #Output: same array, all points of object in (x,y) are set to 2\n",
    "    def set_found_object(self, data0, x, y):\n",
    "        data = data0.copy()\n",
    "        sizeX, sizeY = data.shape\n",
    "\n",
    "        def array_search(x,y,data):\n",
    "            ans,cur = [],[]\n",
    "\n",
    "            if data[x][y] == 1:\n",
    "                cur.append((x,y))\n",
    "\n",
    "            while cur!=[]:\n",
    "                ans += cur\n",
    "                prev = cur.copy()\n",
    "                cur = []\n",
    "\n",
    "                for pnt in prev:\n",
    "                    cur+=get_near(*pnt, data)\n",
    "\n",
    "            return ans \n",
    "\n",
    "        def get_near(x,y,data):\n",
    "            ans = []\n",
    "            for dx in [-1,0,1]:\n",
    "                for dy in [-1,0,1]:\n",
    "                    nx,ny = x+dx,y+dy\n",
    "                    if nx >=0 and nx < sizeX and ny>=0 and ny < sizeY and data[nx][ny]==1:\n",
    "                        data[nx][ny]=2\n",
    "                        ans.append((nx,ny))\n",
    "\n",
    "            if (x,y) in ans:\n",
    "                ans.remove((x,y))\n",
    "            return ans\n",
    "\n",
    "        array_search(x,y,data)\n",
    "        return data\n",
    "    #Input: 2D numpy array data \n",
    "    #Output: list of blobs (blob - a list of points)\n",
    "    def get_blobs(self, data0):\n",
    "        data = data0.copy()\n",
    "\n",
    "        blob,blobs = [],[]\n",
    "        sizeX, sizeY = data.shape\n",
    "\n",
    "        def get_near(x,y,data):\n",
    "            ans = []\n",
    "            for dx in [-1,0,1]:\n",
    "                for dy in [-1,0,1]:\n",
    "                    nx,ny = x+dx,y+dy\n",
    "                    if nx >=0 and nx < sizeX and ny>=0 and ny < sizeY and data[nx][ny]==1:\n",
    "                        data[nx][ny]=2\n",
    "                        ans.append((nx,ny))\n",
    "\n",
    "            if (x,y) in ans:\n",
    "                ans.remove((x,y))\n",
    "            return ans\n",
    "\n",
    "        def array_search(x,y,data):\n",
    "            ans,cur = [],[]\n",
    "\n",
    "            if data[x][y] == 1:\n",
    "                cur.append((x,y))\n",
    "\n",
    "            while cur!=[]:\n",
    "                ans += cur\n",
    "                prev = cur.copy()\n",
    "                cur = []\n",
    "\n",
    "                for pnt in prev:\n",
    "                    cur+=get_near(*pnt, data)\n",
    "\n",
    "            return ans \n",
    "\n",
    "        for x in range(sizeX):\n",
    "            for y in range(sizeY):\n",
    "                if data[x][y] == 1:\n",
    "                    blob = []\n",
    "                    blob+=array_search(x,y,data) #it is appending to blob\n",
    "                    blobs.append(blob)\n",
    "                    #print('Blob',blobs)\n",
    "        return blobs\n",
    "    #Get mean centers of all 1 blobs on 1-0 image.\n",
    "    def get_centers(self,data0):\n",
    "        blobs = self.get_blobs(data0)\n",
    "        #print('Blobs', blobs)\n",
    "\n",
    "        centers = []\n",
    "        for i in range(len(blobs)):\n",
    "            blobs[i] = np.array([[x,y] for x,y in blobs[i]])\n",
    "            centers.append([int(round(blobs[i].T[0].mean())), int(round(blobs[i].T[1].mean()))])\n",
    "\n",
    "        return centers\n",
    "    #Input: 2D numpy array (aka 512,512) with 1 for object pixel and 0 for non object\n",
    "    #Output: same array without blobs with < blob_thres pixel in it\n",
    "    def cut_small_blobs(self, data):    \n",
    "        def remove_blob(data,blob):\n",
    "            for pnt in blob:\n",
    "                data[pnt[0]][pnt[1]] = 0\n",
    "            return data\n",
    "\n",
    "        blobs = self.get_blobs(data)\n",
    "\n",
    "        n_cut = 0\n",
    "        for blob in blobs:\n",
    "            if len(blob) < args['blob_thres']:\n",
    "                n_cut += 1\n",
    "                data = remove_blob(data, blob)\n",
    "\n",
    "        print (\"{0} / {1} blobs cut by blob_tres = {2}\".format(n_cut,len(blobs),args['blob_thres']))\n",
    "        return data\n",
    "    def convolution2d(self, image, kernel):\n",
    "        m, n = kernel.shape\n",
    "        d = m//2\n",
    "        ans = image.copy()\n",
    "        if (m == n):\n",
    "            y, x = image.shape\n",
    "            y = y - m + 1\n",
    "            x = x - m + 1\n",
    "            new_image = np.zeros((y,x))\n",
    "            for i in range(y):\n",
    "                for j in range(x):\n",
    "                    new_image[i][j] = np.sum(image[i:i+m, j:j+m]*kernel)\n",
    "        ans[d:-d,d:-d] = new_image\n",
    "        return ans\n",
    "    def update_TP(self, TP, flux):\n",
    "        for i, limit in enumerate(args['flux_limit']):\n",
    "            if flux > limit:\n",
    "                TP[i] += 1\n",
    "        return TP\n",
    "    #check if there is a source in range 3 pixels - Works in Y paradigm.\n",
    "    def near_source(self, pred, sX, sY):\n",
    "        sizeY,sizeX = pred.shape\n",
    "        x0 = max(0, sX-3)\n",
    "        x1 = min (sizeX - 1, sX+4)\n",
    "        y0 = max(0, sY-3)\n",
    "        y1 = min(sizeY - 1, sY + 4)\n",
    "\n",
    "        #check if at least one pixel belongs to object\n",
    "        return pred[y0:y1,x0:x1].sum() >= 1 \n",
    "    \n",
    "    def boxlist(self):\n",
    "        #Input: 2D numpy array data \n",
    "        #Output: list of blobs (blob - a list of points)\n",
    "        def get_blobs(data0, pmap): #data0 - centers, pmap - probability map\n",
    "            data = data0.copy()\n",
    "\n",
    "            blob,blobs = [],[]\n",
    "            sizeX, sizeY = data.shape\n",
    "\n",
    "            def get_near(x,y,data):\n",
    "                ans = []\n",
    "                for dx in [-1,0,1]:\n",
    "                    for dy in [-1,0,1]:\n",
    "                        nx,ny = x+dx,y+dy\n",
    "                        #Check if it is my center point or it's just less probable\n",
    "                        if (nx >=0 and nx < sizeX and ny>=0 and ny < sizeY) and data[nx][ny]!=2 and \\\n",
    "                            ((data[nx][ny]==1) or (pmap[x][y] >= pmap[nx][ny] >= args['min_object_p'])): #or it's just less probable\n",
    "\n",
    "                            data[nx][ny]=2\n",
    "                            ans.append((nx,ny))\n",
    "\n",
    "                if (x,y) in ans:\n",
    "                    ans.remove((x,y))\n",
    "                return ans\n",
    "\n",
    "            def array_search(x,y,data):\n",
    "                ans,cur = [],[]\n",
    "\n",
    "                if data[x][y] == 1:\n",
    "                    cur.append((x,y))\n",
    "\n",
    "                while cur!=[]:\n",
    "                    ans += cur\n",
    "                    prev = cur.copy()\n",
    "                    cur = []\n",
    "\n",
    "                    for pnt in prev:\n",
    "                        cur+=get_near(*pnt, data)\n",
    "\n",
    "                return ans \n",
    "\n",
    "            for x in range(sizeX):\n",
    "                for y in range(sizeY):\n",
    "                    if data[x][y] == 1:\n",
    "                        blob = []\n",
    "                        blob+=array_search(x,y,data) #it is appending to blob\n",
    "                        blobs.append(blob)\n",
    "                        #print('Blob',blobs)\n",
    "            return blobs #fitst method just to add initial blobs    \n",
    "\n",
    "        #------get some blobs from ans----------\n",
    "        centers = self.ans.copy()\n",
    "        pmap = self.ans.copy()\n",
    "\n",
    "        pmap = gaussian_filter(pmap, sigma = 1)\n",
    "\n",
    "        centers = (centers == maximum_filter(centers,footprint=np.ones((9,9)))) * (pmap > args['min_center_p'])\n",
    "        centers = convolve(centers, np.ones((3,3)), mode='constant', cval=0.0)\n",
    "        centers = centers.astype(int)\n",
    "\n",
    "        blobs = get_blobs(centers, pmap)\n",
    "        print('All blobs', len(blobs))\n",
    "        #cut small blobs\n",
    "        blobs = [blob for blob in blobs if len(blob) > args['min_blob_pixels']]\n",
    "        print('After min blob pixels cut', len(blobs))\n",
    "\n",
    "        \n",
    "        \n",
    "        #-------count noize mean for later use\n",
    "        df = self.df.copy()\n",
    "\n",
    "        def is_noize(row):\n",
    "            return pmap[int(row['X'])][int(row['Y'])] < args['noize_bound']\n",
    "\n",
    "        df['is_noize'] = df.apply(is_noize, axis = 1)\n",
    "        df = df.query('is_noize == True')\n",
    "\n",
    "        S = (pmap < args['noize_bound']).astype(int).sum() #n of noize pixels\n",
    "        noize_p = len(df) / S\n",
    "        print('current noize p',noize_p)\n",
    "        \n",
    "        #-------convert blobs to dataframe src with all information\n",
    "        #OK, now we have some blobs. Extract center and flux from each blob know\n",
    "        src = pd.DataFrame(columns=['FLUX', 'X', 'Y', 'SRC_CTS', 'BKG_CTS'])\n",
    "\n",
    "        #for each blob we need to count number of photons in it \n",
    "        df = self.df\n",
    "        small_blob_N = 0\n",
    "        for blob in blobs:\n",
    "            cur_blob = np.array(blob).T\n",
    "            x0,x1,y0,y1 = cur_blob[0].min(), cur_blob[0].max(), cur_blob[1].min(), cur_blob[1].max()\n",
    "            cur_df = df[df['X'].between(x0,x1) & df['Y'].between(y0,y1)]\n",
    "\n",
    "            X = cur_blob[0]\n",
    "            Y = cur_blob[1]\n",
    "            div = X / Y\n",
    "            res = X - Y\n",
    "            ans = df.query('X in @X and Y in @Y and X/Y in @div')\n",
    "\n",
    "            if len(ans) < args['min_photons_in_blob']:\n",
    "                small_blob_N +=1\n",
    "                continue\n",
    "\n",
    "            blob_pixels = len(blob)\n",
    "            bkg_cts_count = int(noize_p * blob_pixels)\n",
    "            cts = len(ans)\n",
    "            src_cts = cts - bkg_cts_count #len(ans[ans['SRC_ID']!=-1])\n",
    "            bkg_cts_correct = len(ans[ans['SRC_ID']==-1]) #need to estimate from image\n",
    "\n",
    "            box_cts = len(cur_df)\n",
    "            box_size = int((x1-x0+y1-y0+2)/2)\n",
    "            net_rate = src_cts / cts\n",
    "            \n",
    "            #need to conver to absolute\n",
    "            x,y = int(ans['X'].mean()),int(ans['Y'].mean())\n",
    "            like = pmap[x][y] #may not probability?\n",
    "            \n",
    "            x,y = self.frame.to_absolute(x+args.shift_blobs,y+args.shift_blobs) #+10 because of cut_to_sky_df.\n",
    "            ra,dec = ds.my_wcs.all_pix2world(x,y,0)\n",
    "\n",
    "            \n",
    "            flux =  args['mean_ECF'] * (src_cts - bkg_cts_count) / args['exp_k']\n",
    "\n",
    "            src = src.append({'FLUX' : flux, 'X' : x, 'Y' : y, 'RA' : ra, 'DEC' : dec,\n",
    "                        'BLOB_PIXELS' : blob_pixels,\n",
    "                        'CTS': cts, 'BOX_CTS' : box_cts,  'SRC_CTS' : src_cts,\n",
    "                        'BKG_CTS_CORRECT' : bkg_cts_correct, 'BOX_SIZE' : box_size, \n",
    "                        'BKG_CTS_COUNT' : bkg_cts_count,\n",
    "                        'LIKE' : like, 'MEAN_EXP_TIME' : args['exp_k'], 'NET_RATE' : net_rate},\n",
    "                         ignore_index=True)\n",
    "        \n",
    "        \n",
    "        print(f'BLOBS WITH < N photons {small_blob_N}')\n",
    "        print(f'SRC LEN {len(src)}')\n",
    "              \n",
    "        #ADD ERR - just for format\n",
    "        src['SRC_CTS_ERR'] = np.zeros(len(src))\n",
    "        src['FLUX_ERR'] = np.zeros(len(src))\n",
    "        src['NET_RATE_ERR'] = np.zeros(len(src))\n",
    "        src['RA_DEC_ERR'] = np.zeros(len(src))\n",
    "        src = src.sort_values(by = 'FLUX', ascending = False)\n",
    "\n",
    "        self.detected = src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     3,
     43,
     53,
     59,
     75,
     82,
     101,
     113
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###################Other##############################\n",
    "#  A Class for working image processing. Mainly cutting df, arrays\n",
    "############################################################          \n",
    "class Frame():\n",
    "    def __init__(self, x0=0,x1=0,y0=0,y1=0,sizeX=0, sizeY=0):\n",
    "        self.x0 = x0\n",
    "        self.x1 = x1\n",
    "        self.y0 = y0\n",
    "        self.y1 = y1\n",
    "        self.sizeX = x1-x0\n",
    "        self.sizeY = y1-y0\n",
    "    def to_absolute(self, x,y):\n",
    "        return x + self.x0, y + self.y0\n",
    "    def crop_dataframe(self, df):\n",
    "        #All pixels [x0;x1), [y0,y1)\n",
    "        df = df[(df['X'] >= self.x0) & (df['X'] < self.x1) & (df['Y'] >= self.y0) & (df['Y'] < self.y1)]\n",
    "        df['X'] = (df['X'] - self.x0).astype(int)\n",
    "        df['Y'] = (df['Y'] - self.y0).astype(int)\n",
    "        \n",
    "        return df #.reset_index()  #just dataframe for image\n",
    "    def crop_data(self, df, simput):\n",
    "        simput = self.crop_dataframe(simput)\n",
    "        df = self.crop_dataframe(df)\n",
    "        \n",
    "        #Remove objects which centers are not on image\n",
    "        exist_obj = list(simput['SRC_ID']) + [-1]\n",
    "        df = df[df['SRC_ID'].isin(exist_obj)] \n",
    "\n",
    "        #Remove objects which doesn't have photons in df from simput\n",
    "        exist_obj = list(df['SRC_ID'])\n",
    "        simput = simput[simput['SRC_ID'].isin(exist_obj)] \n",
    "        \n",
    "        return df.reset_index(), simput.reset_index() #crop + delete smt\n",
    "    def crop_ndarray(self, array):\n",
    "        return array[self.y0:self.y1,self.x0:self.x1].copy()\n",
    "    def frame_info(self):\n",
    "        print('Image',self.x0,self.x1,self.y0,self.y1)\n",
    "    def __repr__(self):\n",
    "        return str('Frame ' + str(self.x0) +' '+ str(self.x1) +' '+ str(self.y0) +' '+ str(self.y1) )\n",
    "    def load_from_dct(self, ds_dict): #init from dictionary\n",
    "        #np.save('all_frames.npy', np.array([frame.__dict__ for frame in ds2.frames]))\n",
    "        for k, v in ds_dict.items():\n",
    "            setattr(self, k, v)\n",
    "class Pixel():\n",
    "    def __init__(self, p=0, src_id=None, src_color=None):\n",
    "        self.p = p\n",
    "        self.src_id = src_id\n",
    "        self.src_color = src_color\n",
    "    \n",
    "############################################################\n",
    "#  Utils\n",
    "############################################################ \n",
    "#u\n",
    "def read_fits_to_numpy (file):\n",
    "    #im = read_fits_to_numpy('/home/ad.vasilchenko/Astronomy/data/last_simulations/esaas_out/90_islands.fits')\n",
    "    #plt.imshow(im)\n",
    "    #im.shape\n",
    "    #read_fits_to_numpy(args['esaas_path']+\"{n}_islands_{i}.fits\".format(n=90,i=10))\n",
    "    return fits.open(file)[0].data \n",
    "def get_confusion_limit():\n",
    "    #soft\n",
    "    a1s = 1.82\n",
    "    a2s = 0.6\n",
    "    S0s = 1.48 * 10 ** -14\n",
    "    Ns = 6150\n",
    "\n",
    "    S = [10 ** p for p in np.arange(-17,-12,0.02)]\n",
    "    def soft(s):\n",
    "        return Ns * ( ((2 * (10 ** -15))**a1s) / (s**a1s + (S0s ** (a1s-a2s)) * (s**a2s) ))\n",
    "\n",
    "    y1 = [soft(s) for s in S]\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    sns.lineplot(x = S, y = y1)\n",
    "    sns.lineplot(x = [10**-17, 10**-13], y = [N,N])\n",
    "def sample_from_distribution(dist, N):\n",
    "    # Generate a KDE from the empirical sample\n",
    "    sample_pdf = scipy.stats.gaussian_kde(dist)\n",
    "\n",
    "    # Sample new datapoints from the KDE\n",
    "    new_sample_data = sample_pdf.resample(N).T[:,0]\n",
    "    return new_sample_data\n",
    "def grid_plot(img_list):\n",
    "    #Build some good grid plots\n",
    "    import matplotlib as mpl\n",
    "    size = math.ceil(math.sqrt(len(img_list)))\n",
    "    gs = mpl.gridspec.GridSpec(size,size)\n",
    "    gs.update(wspace=0.1, hspace=0.1, left=0.1, right=0.2, bottom=0.1, top=0.2)\n",
    "\n",
    "    fig = plt.figure(figsize=(110, 110))\n",
    "    #fig.suptitle('this is the figure title')\n",
    "\n",
    "    #st = fig.suptitle(\"Unet Prediction with different thresholds\")\n",
    "    for i in range(len(img_list)):\n",
    "        #plt.title('a')\n",
    "        plt.subplot(gs[i])\n",
    "        plt.imshow(img_list[i].astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "\n",
    "    #plt.savefig('Network_Prediction.jpg')\n",
    "    plt.show()\n",
    "def paint_matrix(mats, size = 50):\n",
    "    #print (mats.shape)\n",
    "    fig=plt.figure(figsize=(len(mats)*size, size))\n",
    "    columns = len(mats)\n",
    "\n",
    "    for i in range(1, columns+1):\n",
    "        fig.add_subplot(1, columns, i)\n",
    "        imshow(Image.fromarray(np.uint8(mats[i-1])))# , interpolation='nearest')\n",
    "        plt.grid = False\n",
    "        #plt.axis('on')\n",
    "    plt.colorbar()\n",
    "    plt.show() #matrix - list of numpy arrays.\n",
    "def create_dir(d):\n",
    "    d = os.path.dirname(d)\n",
    "    if not os.path.exists(d):\n",
    "            os.makedirs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create dataset from config, predict, and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erasing /data/kolosovi/dataset_presentation/\n"
     ]
    }
   ],
   "source": [
    "args = Config(data_type = 'test', dataset_type = 'presentation', remove_old = True)\n",
    "\n",
    "args.join_cluster = True #enable clusters\n",
    "args.add_noize = False #don't want extra noize\n",
    "args.conf_limit = args.flux_limit = 6e-15 #don't want to faint sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telescope data preparing\n",
      "Current ERO /srg/a1/work/kate/erosita/agn/2.4.2/1e17/0_4yr_ccdall_eroevt.fits\n",
      "Current EVT /srg/a1/work/kate/erosita/agn/2.4.2/1e17/0_4yr_ccdall_evt.fits\n",
      "Current SIMPUT /srg/a1/work/kate/erosita/agn/2.4.2/1e17/0_agncat.simput\n",
      "Current NOIZE /srg/a1/work/kate/erosita/bkg/for_sim/bkg_0.fits\n",
      "FIRST READ 44510\n",
      "Noize preparing\n",
      "FIRST READ 44510\n",
      "CURRENT EVT /srg/a1/work/kate/erosita/agn/2.4.2/1e17/0_4yr_ccdall_evt.fits\n",
      "ERO LEN 44510\n",
      "EVT LEN 64869\n",
      "MERGE LEN 44065\n",
      "SEC READ 44065\n",
      "Adding cluster data to test\n",
      "FIRST READ 3414\n",
      "Noize preparing\n",
      "FIRST READ 3414\n",
      "CURRENT EVT /srg/a1/work/kate/erosita/clusters/for_rodion/0_4yr_ccdall_evt.fits\n",
      "ERO LEN 3414\n",
      "EVT LEN 4559\n",
      "MERGE LEN 3377\n",
      "SEC READ 3377\n",
      "CLUST LEN 199\n",
      "CLUST LEN 199\n",
      "CURRENT MIN FLUX 2.3e-15\n",
      "NOIZE PHOTONS N (before) 1\n",
      "$$$$ DF CHECK 0\n",
      "$$$$ DF CHECK 0\n",
      "--cut data CLUST LEN 199\n",
      "--cut data CLUST LEN 118\n",
      "--EXAMPLE -1.0\n",
      "$$$$ DF CHECK 0\n",
      "--cut data CLUST LEN 118\n",
      "114630 objects overall;  1949 objects with flux more than 2.3e-15\n",
      "NOIZE PHOTONS N (after) 15797\n",
      "OBJECTS PHOTONS N (after) 31435\n",
      "CLUST LEN 118\n",
      "Reading test frames\n",
      "FRAMES IN THIS DF 36\n",
      "0 Frame 0 512 0 512 not found\n",
      "wwww 73\n",
      "1 Frame 0 512 512 1024 not found\n",
      "wwww 62\n",
      "2 Frame 0 512 1024 1536 not found\n",
      "wwww 64\n",
      "3 Frame 0 512 1536 2048 not found\n",
      "wwww 93\n",
      "4 Frame 0 512 2048 2560 not found\n",
      "wwww 82\n",
      "5 Frame 0 512 2168 2680 not found\n",
      "wwww 76\n",
      "6 Frame 512 1024 0 512 not found\n",
      "wwww 75\n",
      "7 Frame 512 1024 512 1024 not found\n",
      "wwww 58\n",
      "8 Frame 512 1024 1024 1536 not found\n",
      "wwww 67\n",
      "9 Frame 512 1024 1536 2048 not found\n",
      "wwww 71\n",
      "10 Frame 512 1024 2048 2560 not found\n",
      "wwww 82\n",
      "11 Frame 512 1024 2168 2680 not found\n",
      "wwww 69\n",
      "12 Frame 1024 1536 0 512 not found\n",
      "wwww 76\n",
      "13 Frame 1024 1536 512 1024 not found\n",
      "wwww 66\n",
      "14 Frame 1024 1536 1024 1536 not found\n",
      "wwww 76\n",
      "15 Frame 1024 1536 1536 2048 not found\n",
      "wwww 74\n",
      "16 Frame 1024 1536 2048 2560 not found\n",
      "wwww 73\n",
      "17 Frame 1024 1536 2168 2680 not found\n",
      "wwww 72\n",
      "18 Frame 1536 2048 0 512 not found\n",
      "wwww 84\n",
      "19 Frame 1536 2048 512 1024 not found\n",
      "wwww 69\n",
      "20 Frame 1536 2048 1024 1536 not found\n",
      "wwww 63\n",
      "21 Frame 1536 2048 1536 2048 not found\n",
      "wwww 65\n",
      "22 Frame 1536 2048 2048 2560 not found\n",
      "wwww 67\n",
      "23 Frame 1536 2048 2168 2680 not found\n",
      "wwww 73\n",
      "24 Frame 2048 2560 0 512 not found\n",
      "wwww 68\n",
      "25 Frame 2048 2560 512 1024 not found\n",
      "wwww 63\n",
      "26 Frame 2048 2560 1024 1536 not found\n",
      "wwww 71\n",
      "27 Frame 2048 2560 1536 2048 not found\n",
      "wwww 74\n",
      "28 Frame 2048 2560 2048 2560 not found\n",
      "wwww 62\n",
      "29 Frame 2048 2560 2168 2680 not found\n",
      "wwww 67\n",
      "30 Frame 2168 2680 0 512 not found\n",
      "wwww 69\n",
      "31 Frame 2168 2680 512 1024 not found\n",
      "wwww 65\n",
      "32 Frame 2168 2680 1024 1536 not found\n",
      "wwww 71\n",
      "33 Frame 2168 2680 1536 2048 not found\n",
      "wwww 68\n",
      "34 Frame 2168 2680 2048 2560 not found\n",
      "wwww 69\n",
      "35 Frame 2168 2680 2168 2680 not found\n",
      "wwww 72\n",
      "Current ERO /srg/a1/work/kate/erosita/agn/2.4.2/1e17/1_4yr_ccdall_eroevt.fits\n",
      "Current EVT /srg/a1/work/kate/erosita/agn/2.4.2/1e17/1_4yr_ccdall_evt.fits\n",
      "Current SIMPUT /srg/a1/work/kate/erosita/agn/2.4.2/1e17/1_agncat.simput\n",
      "Current NOIZE /srg/a1/work/kate/erosita/bkg/for_sim/bkg_1.fits\n",
      "FIRST READ 44044\n",
      "Noize preparing\n",
      "FIRST READ 44044\n",
      "CURRENT EVT /srg/a1/work/kate/erosita/agn/2.4.2/1e17/1_4yr_ccdall_evt.fits\n",
      "ERO LEN 44044\n",
      "EVT LEN 63971\n",
      "MERGE LEN 43617\n",
      "SEC READ 43617\n",
      "Adding cluster data to test\n",
      "FIRST READ 4502\n",
      "Noize preparing\n",
      "FIRST READ 4502\n",
      "CURRENT EVT /srg/a1/work/kate/erosita/clusters/for_rodion/1_4yr_ccdall_evt.fits\n",
      "ERO LEN 4502\n",
      "EVT LEN 5575\n",
      "MERGE LEN 4461\n",
      "SEC READ 4461\n",
      "CLUST LEN 203\n",
      "CLUST LEN 203\n",
      "CURRENT MIN FLUX 2.3e-15\n",
      "NOIZE PHOTONS N (before) 1\n",
      "$$$$ DF CHECK 0\n",
      "$$$$ DF CHECK 0\n",
      "--cut data CLUST LEN 203\n",
      "--cut data CLUST LEN 107\n",
      "--EXAMPLE 115361.0\n",
      "$$$$ DF CHECK 0\n",
      "--cut data CLUST LEN 107\n",
      "113837 objects overall;  1918 objects with flux more than 2.3e-15\n",
      "NOIZE PHOTONS N (after) 15570\n",
      "OBJECTS PHOTONS N (after) 32398\n",
      "CLUST LEN 107\n",
      "Reading test frames\n",
      "FRAMES IN THIS DF 36\n",
      "36 Frame 0 512 0 512 not found\n",
      "wwww 63\n",
      "37 Frame 0 512 512 1024 not found\n",
      "wwww 76\n",
      "38 Frame 0 512 1024 1536 not found\n",
      "wwww 82\n",
      "39 Frame 0 512 1536 2048 not found\n",
      "wwww 64\n",
      "40 Frame 0 512 2048 2560 not found\n",
      "wwww 57\n",
      "41 Frame 0 512 2168 2680 not found\n",
      "wwww 65\n",
      "42 Frame 512 1024 0 512 not found\n",
      "wwww 89\n",
      "43 Frame 512 1024 512 1024 not found\n",
      "wwww 73\n",
      "44 Frame 512 1024 1024 1536 not found\n",
      "wwww 73\n",
      "45 Frame 512 1024 1536 2048 not found\n",
      "wwww 70\n",
      "46 Frame 512 1024 2048 2560 not found\n",
      "wwww 66\n",
      "47 Frame 512 1024 2168 2680 not found\n",
      "wwww 70\n",
      "48 Frame 1024 1536 0 512 not found\n",
      "wwww 70\n",
      "49 Frame 1024 1536 512 1024 not found\n",
      "wwww 65\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(size = 50, mode = 'test')\n",
    "ds.prepare() \n",
    "ds.predict_all(model)\n",
    "ds.group_ans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args['KDE_bandwidth'] = 3\n",
    "args['p_mask'] = 0.0016 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All blobs 700\n",
      "After min blob pixels cut 700\n",
      "current noize p 0.0035795416337057774\n",
      "BLOBS WITH < N photons 249\n",
      "SRC LEN 451\n",
      "All blobs 341\n",
      "After min blob pixels cut 341\n",
      "current noize p 0.005372739300534031\n",
      "BLOBS WITH < N photons 105\n",
      "SRC LEN 236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['boxlist_0.fits', 'boxlist_1.fits']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving all boxlists to args.nn_res_path\n",
    "args.nn_res_path = '/home/kolosovi/work/data/my_output/final_test'\n",
    "#os.mkdir(args.nn_res_path) \n",
    "\n",
    "ds.save_boxlists2()\n",
    "\n",
    "#Here are the results\n",
    "\n",
    "os.listdir(args.nn_res_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>SRC_CTS</th>\n",
       "      <th>BKG_CTS</th>\n",
       "      <th>BKG_CTS_CORRECT</th>\n",
       "      <th>BKG_CTS_COUNT</th>\n",
       "      <th>BLOB_PIXELS</th>\n",
       "      <th>BOX_CTS</th>\n",
       "      <th>BOX_SIZE</th>\n",
       "      <th>CTS</th>\n",
       "      <th>DEC</th>\n",
       "      <th>LIKE</th>\n",
       "      <th>MEAN_EXP_TIME</th>\n",
       "      <th>NET_RATE</th>\n",
       "      <th>RA</th>\n",
       "      <th>SRC_CTS_ERR</th>\n",
       "      <th>FLUX_ERR</th>\n",
       "      <th>NET_RATE_ERR</th>\n",
       "      <th>RA_DEC_ERR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1.365237e-12</td>\n",
       "      <td>1994</td>\n",
       "      <td>2532</td>\n",
       "      <td>869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>2.825639103862215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7710214477559809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>9.661916e-13</td>\n",
       "      <td>949</td>\n",
       "      <td>741</td>\n",
       "      <td>615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>0.8361100258236619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.9327935249465882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>6.959722e-13</td>\n",
       "      <td>1382</td>\n",
       "      <td>170</td>\n",
       "      <td>443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0.2018818101559565</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.4516857254268971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3.896187e-13</td>\n",
       "      <td>1166</td>\n",
       "      <td>2320</td>\n",
       "      <td>248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>2.590402445410295</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.691834211779877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.450828e-13</td>\n",
       "      <td>139</td>\n",
       "      <td>1623</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.8156096663513364</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.8331935692655468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2.309434e-13</td>\n",
       "      <td>508</td>\n",
       "      <td>524</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.5949911623118956</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.422639636446166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2.073777e-13</td>\n",
       "      <td>850</td>\n",
       "      <td>1715</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.9182328543675242</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.043058351517957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.948094e-13</td>\n",
       "      <td>164</td>\n",
       "      <td>2655</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.961684840151255</td>\n",
       "      <td>0.999036</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>2.806101327199216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.775279e-13</td>\n",
       "      <td>759</td>\n",
       "      <td>1015</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.140481303867983</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.991304</td>\n",
       "      <td>2.1439836383409085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1.759569e-13</td>\n",
       "      <td>1445</td>\n",
       "      <td>2385</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.6626055625323364</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.3815702821526035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1.665306e-13</td>\n",
       "      <td>1218</td>\n",
       "      <td>1962</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.192731086784486</td>\n",
       "      <td>0.999550</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.6339839093122257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.445360e-13</td>\n",
       "      <td>168</td>\n",
       "      <td>1658</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.8545106586743931</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.800995795730574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1.445360e-13</td>\n",
       "      <td>1280</td>\n",
       "      <td>1093</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.2272165488333404</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.5650210941793448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1.413939e-13</td>\n",
       "      <td>1526</td>\n",
       "      <td>2414</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.694802009807621</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.29148924057759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.398229e-13</td>\n",
       "      <td>745</td>\n",
       "      <td>1165</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.3071294158566993</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.159590186502473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.382518e-13</td>\n",
       "      <td>96</td>\n",
       "      <td>1064</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.1946491479620986</td>\n",
       "      <td>0.998415</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>2.8805760118438273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1.382518e-13</td>\n",
       "      <td>1282</td>\n",
       "      <td>1736</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.9416498086520382</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.56281889930692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.351097e-13</td>\n",
       "      <td>1099</td>\n",
       "      <td>1608</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.7994153590560993</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.7662437987539386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.335387e-13</td>\n",
       "      <td>243</td>\n",
       "      <td>2532</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.825229784046992</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.7182012518257066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1.319676e-13</td>\n",
       "      <td>1671</td>\n",
       "      <td>1687</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.8871701409002328</td>\n",
       "      <td>0.999215</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.1303755742497736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.303966e-13</td>\n",
       "      <td>710</td>\n",
       "      <td>729</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.8227412643563233</td>\n",
       "      <td>0.998205</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>2.1983289288593353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1.225414e-13</td>\n",
       "      <td>1892</td>\n",
       "      <td>1015</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.1404876240404718</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884920807766744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.209703e-13</td>\n",
       "      <td>213</td>\n",
       "      <td>1568</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.754573365978407</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.750938187040877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1.209703e-13</td>\n",
       "      <td>1925</td>\n",
       "      <td>637</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.7205500926425814</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.8483771293865904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.115441e-13</td>\n",
       "      <td>265</td>\n",
       "      <td>388</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.443905380087987</td>\n",
       "      <td>0.999071</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.692445752544673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.099730e-13</td>\n",
       "      <td>1089</td>\n",
       "      <td>1775</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.9849582294449497</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.7773835160197118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.068309e-13</td>\n",
       "      <td>583</td>\n",
       "      <td>354</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.4061934700247427</td>\n",
       "      <td>0.999188</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.3392595051270355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.068309e-13</td>\n",
       "      <td>296</td>\n",
       "      <td>1051</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.1803107102644483</td>\n",
       "      <td>0.995823</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>2.658410331129838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1.036889e-13</td>\n",
       "      <td>1233</td>\n",
       "      <td>1726</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.930536465213778</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.6172922681818036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.036889e-13</td>\n",
       "      <td>948</td>\n",
       "      <td>2384</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.661424250703941</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.9342668163268002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>988</td>\n",
       "      <td>1104</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.2394106610369502</td>\n",
       "      <td>0.915575</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.889532500022547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1061</td>\n",
       "      <td>2255</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.518182708197968</td>\n",
       "      <td>0.970938</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.8085866102408263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1048</td>\n",
       "      <td>1854</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0727188517067283</td>\n",
       "      <td>0.980770</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.8229764970817999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>676</td>\n",
       "      <td>569</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.6450032919806639</td>\n",
       "      <td>0.947067</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.2360422643292805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>517</td>\n",
       "      <td>1870</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0902623732678802</td>\n",
       "      <td>0.946251</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.4132667765843125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>761</td>\n",
       "      <td>403</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.46063374802313617</td>\n",
       "      <td>0.992539</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.141561963589658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>762</td>\n",
       "      <td>1719</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.9226429697924645</td>\n",
       "      <td>0.972144</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.140879186272298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>933</td>\n",
       "      <td>498</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5661693565013971</td>\n",
       "      <td>0.911249</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.9505153721807569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>2461</td>\n",
       "      <td>92</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.1152354455193107</td>\n",
       "      <td>0.943058</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.2533432015346997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1184</td>\n",
       "      <td>1357</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.5205417832108652</td>\n",
       "      <td>0.715591</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.671733558068383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1372</td>\n",
       "      <td>1251</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.4027706306992163</td>\n",
       "      <td>0.938347</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.4627736245601886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1994</td>\n",
       "      <td>731</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.8249576380216975</td>\n",
       "      <td>0.965260</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.7716878714369383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>384</td>\n",
       "      <td>2388</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.6654864581073245</td>\n",
       "      <td>0.959148</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.5613703487938295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1664</td>\n",
       "      <td>1191</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.336077992491188</td>\n",
       "      <td>0.839055</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.1382482080462832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1661</td>\n",
       "      <td>874</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.9838766626753473</td>\n",
       "      <td>0.967211</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.1416399842280538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>277</td>\n",
       "      <td>2439</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.722008402349483</td>\n",
       "      <td>0.977719</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.680348411255553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>335</td>\n",
       "      <td>1560</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.7457720151653537</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.615373714254182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1509</td>\n",
       "      <td>920</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.034997607469086</td>\n",
       "      <td>0.894674</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.3105385177540692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1470</td>\n",
       "      <td>1796</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.008306520766585</td>\n",
       "      <td>0.879674</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.3538121046019485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1416</td>\n",
       "      <td>133</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.16079236343715766</td>\n",
       "      <td>0.936701</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.4139190784536153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1391</td>\n",
       "      <td>2630</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.934691604873158</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.4416153467201724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>504</td>\n",
       "      <td>1789</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0002738762523027</td>\n",
       "      <td>0.866468</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.4276781816113466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>408</td>\n",
       "      <td>60</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.07971550475106012</td>\n",
       "      <td>0.962518</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.5334671102398154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>409</td>\n",
       "      <td>673</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.7604661402778535</td>\n",
       "      <td>0.961977</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.532677883096537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1939</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.05862655350482562</td>\n",
       "      <td>0.892974</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.8330256166764639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1346</td>\n",
       "      <td>1375</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.5405485880703964</td>\n",
       "      <td>0.871872</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.4916706025861912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1338</td>\n",
       "      <td>875</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.9850069247168066</td>\n",
       "      <td>0.969950</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.500562560408717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>422</td>\n",
       "      <td>2286</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.5522491617734278</td>\n",
       "      <td>0.628699</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.5190722599174435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1978</td>\n",
       "      <td>810</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.9127212117458104</td>\n",
       "      <td>0.952114</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.7894349616199952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1.885252e-14</td>\n",
       "      <td>1456</td>\n",
       "      <td>1818</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0327502006129676</td>\n",
       "      <td>0.933420</td>\n",
       "      <td>1190.29182</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.3693750578650827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FLUX     X     Y SRC_CTS  BKG_CTS  BKG_CTS_CORRECT  \\\n",
       "355  1.365237e-12  1994  2532     869      NaN              0.0   \n",
       "167  9.661916e-13   949   741     615      NaN              1.0   \n",
       "246  6.959722e-13  1382   170     443      NaN              0.0   \n",
       "211  3.896187e-13  1166  2320     248      NaN              2.0   \n",
       "27   2.450828e-13   139  1623     156      NaN              0.0   \n",
       "106  2.309434e-13   508   524     147      NaN              3.0   \n",
       "151  2.073777e-13   850  1715     132      NaN              0.0   \n",
       "35   1.948094e-13   164  2655     125      NaN              0.0   \n",
       "134  1.775279e-13   759  1015     114      NaN              2.0   \n",
       "261  1.759569e-13  1445  2385     112      NaN              1.0   \n",
       "219  1.665306e-13  1218  1962     106      NaN              0.0   \n",
       "36   1.445360e-13   168  1658      92      NaN              0.0   \n",
       "233  1.445360e-13  1280  1093      92      NaN              0.0   \n",
       "278  1.413939e-13  1526  2414      90      NaN              3.0   \n",
       "131  1.398229e-13   745  1165      89      NaN              1.0   \n",
       "20   1.382518e-13    96  1064      89      NaN              0.0   \n",
       "234  1.382518e-13  1282  1736      88      NaN              0.0   \n",
       "198  1.351097e-13  1099  1608      86      NaN              0.0   \n",
       "54   1.335387e-13   243  2532      85      NaN              0.0   \n",
       "304  1.319676e-13  1671  1687      84      NaN              1.0   \n",
       "130  1.303966e-13   710   729      84      NaN              0.0   \n",
       "339  1.225414e-13  1892  1015      78      NaN              0.0   \n",
       "46   1.209703e-13   213  1568      77      NaN              0.0   \n",
       "346  1.209703e-13  1925   637      78      NaN              0.0   \n",
       "58   1.115441e-13   265   388      71      NaN              0.0   \n",
       "195  1.099730e-13  1089  1775      70      NaN              2.0   \n",
       "114  1.068309e-13   583   354      68      NaN              1.0   \n",
       "65   1.068309e-13   296  1051      69      NaN              0.0   \n",
       "223  1.036889e-13  1233  1726      66      NaN              0.0   \n",
       "168  1.036889e-13   948  2384      66      NaN              1.0   \n",
       "..            ...   ...   ...     ...      ...              ...   \n",
       "177  1.885252e-14   988  1104      13      NaN              0.0   \n",
       "191  1.885252e-14  1061  2255      13      NaN              0.0   \n",
       "189  1.885252e-14  1048  1854      13      NaN              0.0   \n",
       "126  1.885252e-14   676   569      13      NaN              1.0   \n",
       "107  1.885252e-14   517  1870      13      NaN              2.0   \n",
       "136  1.885252e-14   761   403      13      NaN              0.0   \n",
       "137  1.885252e-14   762  1719      13      NaN              0.0   \n",
       "162  1.885252e-14   933   498      13      NaN              0.0   \n",
       "374  1.885252e-14  2461    92      13      NaN              0.0   \n",
       "214  1.885252e-14  1184  1357      13      NaN              6.0   \n",
       "243  1.885252e-14  1372  1251      13      NaN              4.0   \n",
       "356  1.885252e-14  1994   731      13      NaN              0.0   \n",
       "84   1.885252e-14   384  2388      13      NaN              2.0   \n",
       "302  1.885252e-14  1664  1191      13      NaN              3.0   \n",
       "300  1.885252e-14  1661   874      13      NaN              0.0   \n",
       "60   1.885252e-14   277  2439      13      NaN              0.0   \n",
       "75   1.885252e-14   335  1560      13      NaN              1.0   \n",
       "274  1.885252e-14  1509   920      13      NaN              0.0   \n",
       "266  1.885252e-14  1470  1796      13      NaN              0.0   \n",
       "256  1.885252e-14  1416   133      13      NaN              0.0   \n",
       "252  1.885252e-14  1391  2630      13      NaN              1.0   \n",
       "104  1.885252e-14   504  1789      13      NaN              7.0   \n",
       "86   1.885252e-14   408    60      13      NaN              0.0   \n",
       "87   1.885252e-14   409   673      13      NaN              2.0   \n",
       "348  1.885252e-14  1939    41      13      NaN              1.0   \n",
       "240  1.885252e-14  1346  1375      13      NaN              4.0   \n",
       "238  1.885252e-14  1338   875      13      NaN              2.0   \n",
       "91   1.885252e-14   422  2286      13      NaN              5.0   \n",
       "353  1.885252e-14  1978   810      13      NaN              0.0   \n",
       "264  1.885252e-14  1456  1818      13      NaN              1.0   \n",
       "\n",
       "     BKG_CTS_COUNT  BLOB_PIXELS  BOX_CTS  BOX_SIZE    CTS  \\\n",
       "355            0.0        229.0    914.0      17.0  869.0   \n",
       "167            0.0        231.0    638.0      17.0  615.0   \n",
       "246            0.0        236.0    462.0      17.0  443.0   \n",
       "211            0.0        238.0    262.0      18.0  248.0   \n",
       "27             0.0        228.0    159.0      16.0  156.0   \n",
       "106            0.0        239.0    172.0      20.0  147.0   \n",
       "151            0.0        241.0    133.0      17.0  132.0   \n",
       "35             1.0        309.0    131.0      20.0  126.0   \n",
       "134            1.0        294.0    122.0      22.0  115.0   \n",
       "261            0.0        238.0    112.0      17.0  112.0   \n",
       "219            0.0        241.0    108.0      17.0  106.0   \n",
       "36             0.0        235.0     94.0      17.0   92.0   \n",
       "233            0.0        231.0     96.0      17.0   92.0   \n",
       "278            0.0        236.0     93.0      17.0   90.0   \n",
       "131            0.0        245.0     92.0      18.0   89.0   \n",
       "20             1.0        272.0     95.0      19.0   90.0   \n",
       "234            0.0        226.0     91.0      17.0   88.0   \n",
       "198            0.0        241.0     90.0      17.0   86.0   \n",
       "54             0.0        228.0     89.0      17.0   85.0   \n",
       "304            0.0        230.0     85.0      17.0   84.0   \n",
       "130            1.0        246.0     88.0      17.0   85.0   \n",
       "339            0.0        232.0     79.0      16.0   78.0   \n",
       "46             0.0        242.0     83.0      17.0   77.0   \n",
       "346            1.0        260.0     81.0      18.0   79.0   \n",
       "58             0.0        243.0     73.0      17.0   71.0   \n",
       "195            0.0        229.0     74.0      17.0   70.0   \n",
       "114            0.0        233.0     70.0      17.0   68.0   \n",
       "65             1.0        258.0     75.0      18.0   70.0   \n",
       "223            0.0        233.0     67.0      17.0   66.0   \n",
       "168            0.0        242.0     69.0      17.0   66.0   \n",
       "..             ...          ...      ...       ...    ...   \n",
       "177            1.0        292.0     15.0      19.0   14.0   \n",
       "191            1.0        282.0     14.0      19.0   14.0   \n",
       "189            1.0        261.0     16.0      18.0   14.0   \n",
       "126            1.0        267.0     14.0      18.0   14.0   \n",
       "107            1.0        288.0     14.0      19.0   14.0   \n",
       "136            1.0        263.0     14.0      18.0   14.0   \n",
       "137            1.0        298.0     16.0      19.0   14.0   \n",
       "162            1.0        254.0     15.0      18.0   14.0   \n",
       "374            1.0        295.0     15.0      20.0   14.0   \n",
       "214            1.0        386.0     14.0      23.0   14.0   \n",
       "243            1.0        329.0     15.0      21.0   14.0   \n",
       "356            1.0        263.0     15.0      18.0   14.0   \n",
       "84             1.0        266.0     14.0      18.0   14.0   \n",
       "302            1.0        328.0     15.0      21.0   14.0   \n",
       "300            1.0        291.0     15.0      19.0   14.0   \n",
       "60             1.0        274.0     14.0      18.0   14.0   \n",
       "75             1.0        305.0     16.0      21.0   14.0   \n",
       "274            1.0        255.0     15.0      18.0   14.0   \n",
       "266            1.0        246.0     14.0      18.0   14.0   \n",
       "256            1.0        300.0     14.0      20.0   14.0   \n",
       "252            1.0        285.0     14.0      19.0   14.0   \n",
       "104            1.0        271.0     15.0      18.0   14.0   \n",
       "86             1.0        289.0     14.0      19.0   14.0   \n",
       "87             1.0        284.0     14.0      18.0   14.0   \n",
       "348            1.0        326.0     15.0      21.0   14.0   \n",
       "240            1.0        332.0     15.0      21.0   14.0   \n",
       "238            1.0        276.0     14.0      19.0   14.0   \n",
       "91             1.0        382.0     14.0      24.0   14.0   \n",
       "353            1.0        267.0     14.0      18.0   14.0   \n",
       "264            1.0        309.0     15.0      20.0   14.0   \n",
       "\n",
       "                     DEC      LIKE  MEAN_EXP_TIME  NET_RATE  \\\n",
       "355    2.825639103862215  1.000000     1190.29182  1.000000   \n",
       "167   0.8361100258236619  1.000000     1190.29182  1.000000   \n",
       "246   0.2018818101559565  0.999997     1190.29182  1.000000   \n",
       "211    2.590402445410295  0.999998     1190.29182  1.000000   \n",
       "27    1.8156096663513364  0.999976     1190.29182  1.000000   \n",
       "106   0.5949911623118956  0.999860     1190.29182  1.000000   \n",
       "151   1.9182328543675242  0.999736     1190.29182  1.000000   \n",
       "35     2.961684840151255  0.999036     1190.29182  0.992063   \n",
       "134    1.140481303867983  0.999297     1190.29182  0.991304   \n",
       "261   2.6626055625323364  0.999787     1190.29182  1.000000   \n",
       "219    2.192731086784486  0.999550     1190.29182  1.000000   \n",
       "36    1.8545106586743931  0.999602     1190.29182  1.000000   \n",
       "233   1.2272165488333404  0.999874     1190.29182  1.000000   \n",
       "278    2.694802009807621  0.999881     1190.29182  1.000000   \n",
       "131   1.3071294158566993  0.999432     1190.29182  1.000000   \n",
       "20    1.1946491479620986  0.998415     1190.29182  0.988889   \n",
       "234   1.9416498086520382  0.999802     1190.29182  1.000000   \n",
       "198   1.7994153590560993  0.999722     1190.29182  1.000000   \n",
       "54     2.825229784046992  0.999908     1190.29182  1.000000   \n",
       "304   1.8871701409002328  0.999215     1190.29182  1.000000   \n",
       "130   0.8227412643563233  0.998205     1190.29182  0.988235   \n",
       "339   1.1404876240404718  0.999530     1190.29182  1.000000   \n",
       "46     1.754573365978407  0.999408     1190.29182  1.000000   \n",
       "346   0.7205500926425814  0.996410     1190.29182  0.987342   \n",
       "58     0.443905380087987  0.999071     1190.29182  1.000000   \n",
       "195   1.9849582294449497  0.999638     1190.29182  1.000000   \n",
       "114   0.4061934700247427  0.999188     1190.29182  1.000000   \n",
       "65    1.1803107102644483  0.995823     1190.29182  0.985714   \n",
       "223    1.930536465213778  0.999823     1190.29182  1.000000   \n",
       "168    2.661424250703941  0.999323     1190.29182  1.000000   \n",
       "..                   ...       ...            ...       ...   \n",
       "177   1.2394106610369502  0.915575     1190.29182  0.928571   \n",
       "191    2.518182708197968  0.970938     1190.29182  0.928571   \n",
       "189   2.0727188517067283  0.980770     1190.29182  0.928571   \n",
       "126   0.6450032919806639  0.947067     1190.29182  0.928571   \n",
       "107   2.0902623732678802  0.946251     1190.29182  0.928571   \n",
       "136  0.46063374802313617  0.992539     1190.29182  0.928571   \n",
       "137   1.9226429697924645  0.972144     1190.29182  0.928571   \n",
       "162   0.5661693565013971  0.911249     1190.29182  0.928571   \n",
       "374   0.1152354455193107  0.943058     1190.29182  0.928571   \n",
       "214   1.5205417832108652  0.715591     1190.29182  0.928571   \n",
       "243   1.4027706306992163  0.938347     1190.29182  0.928571   \n",
       "356   0.8249576380216975  0.965260     1190.29182  0.928571   \n",
       "84    2.6654864581073245  0.959148     1190.29182  0.928571   \n",
       "302    1.336077992491188  0.839055     1190.29182  0.928571   \n",
       "300   0.9838766626753473  0.967211     1190.29182  0.928571   \n",
       "60     2.722008402349483  0.977719     1190.29182  0.928571   \n",
       "75    1.7457720151653537  0.829787     1190.29182  0.928571   \n",
       "274    1.034997607469086  0.894674     1190.29182  0.928571   \n",
       "266    2.008306520766585  0.879674     1190.29182  0.928571   \n",
       "256  0.16079236343715766  0.936701     1190.29182  0.928571   \n",
       "252    2.934691604873158  0.951564     1190.29182  0.928571   \n",
       "104   2.0002738762523027  0.866468     1190.29182  0.928571   \n",
       "86   0.07971550475106012  0.962518     1190.29182  0.928571   \n",
       "87    0.7604661402778535  0.961977     1190.29182  0.928571   \n",
       "348  0.05862655350482562  0.892974     1190.29182  0.928571   \n",
       "240   1.5405485880703964  0.871872     1190.29182  0.928571   \n",
       "238   0.9850069247168066  0.969950     1190.29182  0.928571   \n",
       "91    2.5522491617734278  0.628699     1190.29182  0.928571   \n",
       "353   0.9127212117458104  0.952114     1190.29182  0.928571   \n",
       "264   2.0327502006129676  0.933420     1190.29182  0.928571   \n",
       "\n",
       "                     RA  SRC_CTS_ERR  FLUX_ERR  NET_RATE_ERR  RA_DEC_ERR  \n",
       "355  0.7710214477559809          0.0       0.0           0.0         0.0  \n",
       "167  1.9327935249465882          0.0       0.0           0.0         0.0  \n",
       "246  1.4516857254268971          0.0       0.0           0.0         0.0  \n",
       "211   1.691834211779877          0.0       0.0           0.0         0.0  \n",
       "27   2.8331935692655468          0.0       0.0           0.0         0.0  \n",
       "106   2.422639636446166          0.0       0.0           0.0         0.0  \n",
       "151   2.043058351517957          0.0       0.0           0.0         0.0  \n",
       "35    2.806101327199216          0.0       0.0           0.0         0.0  \n",
       "134  2.1439836383409085          0.0       0.0           0.0         0.0  \n",
       "261  1.3815702821526035          0.0       0.0           0.0         0.0  \n",
       "219  1.6339839093122257          0.0       0.0           0.0         0.0  \n",
       "36    2.800995795730574          0.0       0.0           0.0         0.0  \n",
       "233  1.5650210941793448          0.0       0.0           0.0         0.0  \n",
       "278    1.29148924057759          0.0       0.0           0.0         0.0  \n",
       "131   2.159590186502473          0.0       0.0           0.0         0.0  \n",
       "20   2.8805760118438273          0.0       0.0           0.0         0.0  \n",
       "234    1.56281889930692          0.0       0.0           0.0         0.0  \n",
       "198  1.7662437987539386          0.0       0.0           0.0         0.0  \n",
       "54   2.7182012518257066          0.0       0.0           0.0         0.0  \n",
       "304  1.1303755742497736          0.0       0.0           0.0         0.0  \n",
       "130  2.1983289288593353          0.0       0.0           0.0         0.0  \n",
       "339   0.884920807766744          0.0       0.0           0.0         0.0  \n",
       "46    2.750938187040877          0.0       0.0           0.0         0.0  \n",
       "346  0.8483771293865904          0.0       0.0           0.0         0.0  \n",
       "58    2.692445752544673          0.0       0.0           0.0         0.0  \n",
       "195  1.7773835160197118          0.0       0.0           0.0         0.0  \n",
       "114  2.3392595051270355          0.0       0.0           0.0         0.0  \n",
       "65    2.658410331129838          0.0       0.0           0.0         0.0  \n",
       "223  1.6172922681818036          0.0       0.0           0.0         0.0  \n",
       "168  1.9342668163268002          0.0       0.0           0.0         0.0  \n",
       "..                  ...          ...       ...           ...         ...  \n",
       "177   1.889532500022547          0.0       0.0           0.0         0.0  \n",
       "191  1.8085866102408263          0.0       0.0           0.0         0.0  \n",
       "189  1.8229764970817999          0.0       0.0           0.0         0.0  \n",
       "126  2.2360422643292805          0.0       0.0           0.0         0.0  \n",
       "107  2.4132667765843125          0.0       0.0           0.0         0.0  \n",
       "136   2.141561963589658          0.0       0.0           0.0         0.0  \n",
       "137   2.140879186272298          0.0       0.0           0.0         0.0  \n",
       "162  1.9505153721807569          0.0       0.0           0.0         0.0  \n",
       "374  0.2533432015346997          0.0       0.0           0.0         0.0  \n",
       "214   1.671733558068383          0.0       0.0           0.0         0.0  \n",
       "243  1.4627736245601886          0.0       0.0           0.0         0.0  \n",
       "356  0.7716878714369383          0.0       0.0           0.0         0.0  \n",
       "84   2.5613703487938295          0.0       0.0           0.0         0.0  \n",
       "302  1.1382482080462832          0.0       0.0           0.0         0.0  \n",
       "300  1.1416399842280538          0.0       0.0           0.0         0.0  \n",
       "60    2.680348411255553          0.0       0.0           0.0         0.0  \n",
       "75    2.615373714254182          0.0       0.0           0.0         0.0  \n",
       "274  1.3105385177540692          0.0       0.0           0.0         0.0  \n",
       "266  1.3538121046019485          0.0       0.0           0.0         0.0  \n",
       "256  1.4139190784536153          0.0       0.0           0.0         0.0  \n",
       "252  1.4416153467201724          0.0       0.0           0.0         0.0  \n",
       "104  2.4276781816113466          0.0       0.0           0.0         0.0  \n",
       "86   2.5334671102398154          0.0       0.0           0.0         0.0  \n",
       "87    2.532677883096537          0.0       0.0           0.0         0.0  \n",
       "348  0.8330256166764639          0.0       0.0           0.0         0.0  \n",
       "240  1.4916706025861912          0.0       0.0           0.0         0.0  \n",
       "238   1.500562560408717          0.0       0.0           0.0         0.0  \n",
       "91   2.5190722599174435          0.0       0.0           0.0         0.0  \n",
       "353  0.7894349616199952          0.0       0.0           0.0         0.0  \n",
       "264  1.3693750578650827          0.0       0.0           0.0         0.0  \n",
       "\n",
       "[377 rows x 20 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last boxlist file\n",
    "ds.cur_src"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
